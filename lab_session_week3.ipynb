{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra and Linear Regression\n",
    "\n",
    "### 13th October 2015 Neil Lawrence\n",
    "\n",
    "\n",
    "## Sum of Squares Error\n",
    "\n",
    "Last week we considered a cost function for minimization of the error. We considered items (films) and users and assumed that each movie rating, $y_{i,j}$ could be summarised by an inner product between a vector associated with the item, $\\mathbf{v}_j$ and one associated with the user $\n",
    "\\mathbf{u}_i$. We justified the inner product as a measure of similarity in the space of 'movie subjects', where both the users and the items lived, giving the analogy of a library.\n",
    "\n",
    "To make predictions we encouraged the similarity to be high if the movie rating was high using the quadratic error function,\n",
    "$$\n",
    "E_{i,j}(\\mathbf{u}_i, \\mathbf{v}_j) = \\left(\\mathbf{u}_i^\\top \\mathbf{v}_j - y_{i,j}\\right)^2,\n",
    "$$\n",
    "which we then summed across all the observations to form the total error\n",
    "$$\n",
    "E(\\mathbf{U}, \\mathbf{V}) = \\sum_{i,j}s_{i,j}\\left(\\mathbf{u}_i^\\top \\mathbf{v}_j - y_{i,j}\\right)^2,\n",
    "$$\n",
    "where $s_{i,j}$ is an indicator variable which is set to 1 if the rating of movie $j$ by user $i$ is provided in our data set. \n",
    "\n",
    "This is known as a sum of squares error. Minimizing it was first proposed by [Legendre](http://en.wikipedia.org/wiki/Adrien-Marie_Legendre) in 1805. His book, which was on the orbit of comets, is available on google books, we can take a look at the relevant page by calling the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe frameborder=\"0\" scrolling=\"yes\" style=\"border:0px\" src=\"http://books.google.co.uk/books?id=spcAAAAAMAAJ&pg=PA72&output=embed\", width=700 height=500></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pods\n",
    "pods.notebook.display_google_book(id='spcAAAAAMAAJ', page=72) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the main text is in French, but the key part we are interested in can be roughly translated as\n",
    "\n",
    "\"In most matters where we take measures data through observation, the most accurate results they can offer, it is almost always leads to a system of equations of the form\n",
    "$$E = a + bx + cy + fz + etc .$$\n",
    "where a, b, c, f etc are the known coefficients and  x , y, z etc are unknown and must be determined by the condition that the value of E is reduced, for each equation, to an amount or zero or very small.\"\n",
    "\n",
    "He continues\n",
    "\n",
    "\"Of all the principles that we can offer for this item, I think it is not broader, more accurate, nor easier than the one we have used in previous research application, and that is to make the minimum sum of the squares of the errors. By this means, it is between the errors a kind of balance that prevents extreme to prevail, is very specific to make known the state of the closest to the truth system. The sum of the squares of the errors $E^2 + \\left.E^\\prime\\right.^2 + \\left.E^{\\prime\\prime}\\right.^2 + etc$ being\n",
    "\\begin{align*}   &(a + bx + cy + fz + etc)^2 \\\\\n",
    "+ &(a^\\prime + b^\\prime x + c^\\prime y + f^\\prime z + etc ) ^2\\\\\n",
    "+ &(a^{\\prime\\prime} + b^{\\prime\\prime}x  + c^{\\prime\\prime}y +  f^{\\prime\\prime}z + etc )^2 \\\\\n",
    "+ & etc\n",
    "\\end{align*}\n",
    "if we wanted a minimum, by varying x alone, we will have the equation ...\"\n",
    "\n",
    "This is the earliest know printed version of the problem of least squares. The notation, however, is a little awkward for mordern eyes. In particular Legendre doesn't make use of the sum sign,\n",
    "$$\n",
    "\\sum_{i=1}^3 z_i = z_1 + z_2 + z_3\n",
    "$$\n",
    "nor does he make use of the inner product. \n",
    "\n",
    "In our notation, if we were to do linear regression, we would need to subsititue:\n",
    "\\begin{align*}\n",
    "a &\\leftarrow y_1-c, \\\\ a^\\prime &\\leftarrow y_2-c,\\\\ a^{\\prime\\prime} &\\leftarrow y_3 -c,\\\\ \n",
    "\\text{etc.} \n",
    "\\end{align*}\n",
    "to introduce the data observations $\\{y_i\\}_{i=1}^{n}$ alongside $c$, the offset. We would then introduce the input locations\n",
    "\\begin{align*}\n",
    "b & \\leftarrow x_1,\\\\\n",
    "b^\\prime & \\leftarrow x_2,\\\\\n",
    "b^{\\prime\\prime} & \\leftarrow x_3\\\\\n",
    "\\text{etc.}\n",
    "\\end{align*}\n",
    "and finally the gradient of the function\n",
    "$$x \\leftarrow -m.$$\n",
    "The remaining coefficients ($c$ and $f$) would then be zero. That would give us \n",
    "\\begin{align*}   &(y_1 - (mx_1+c))^2 \\\\\n",
    "+ &(y_2 -(mx_2 + c))^2\\\\\n",
    "+ &(y_3 -(mx_3 + c))^2 \\\\\n",
    "+ & \\text{etc.}\n",
    "\\end{align*}\n",
    "which we would write in the modern notation for sums as\n",
    "$$\n",
    "\\sum_{i=1}^n (y_i-(mx_i + c))^2\n",
    "$$\n",
    "which is recognised as the sum of squares error for a linear regression.\n",
    "\n",
    "This shows the advantage of modern [summation operator](http://en.wikipedia.org/wiki/Summation), $\\sum$,  in keeping our mathematical notation compact. Whilst it may look more complicated the first time you see it, understanding the mathematical rules that go around it, allows us to go much further with the notation.\n",
    "\n",
    "Inner products (or [dot products](http://en.wikipedia.org/wiki/Dot_product)) are similar. They allow us to write\n",
    "$$\n",
    "\\sum_{i=1}^q u_i v_i\n",
    "$$\n",
    "in a more compact notation,\n",
    "$\n",
    "\\mathbf{u}\\cdot\\mathbf{v}.\n",
    "$\n",
    "\n",
    "Here we are using bold face to represent vectors, and we assume that the individual elements of a vector $\\mathbf{z}$ are given as a series of scalars\n",
    "$$\n",
    "\\mathbf{z} = \\begin{bmatrix} z_1\\\\ z_2\\\\ \\vdots\\\\ z_n \\end{bmatrix}\n",
    "$$\n",
    "which are each indexed by their position in the vector.\n",
    "\n",
    "## Linear Algebra\n",
    "\n",
    "Linear algebra provides a very similar role, when we introduce [linear algebra](http://en.wikipedia.org/wiki/Linear_algebra), it is because we are faced with a large number of addition and multiplication operations. These operations need to be done together and would be very tedious to write down as a group. So the first reason we reach for linear algebra is for a more compact representation of our mathematical formulae. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Example: Olympic Marathons\n",
    "\n",
    "Now we will load in the Olympic marathon data. This is data of the olympic marath times for the men's marathon from the first olympics in 1896 up until the London 2012 olympics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.olympic_marathon_men()\n",
    "x = data['X']\n",
    "y = data['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see what these values are by typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1896.]\n",
      " [1900.]\n",
      " [1904.]\n",
      " [1908.]\n",
      " [1912.]\n",
      " [1920.]\n",
      " [1924.]\n",
      " [1928.]\n",
      " [1932.]\n",
      " [1936.]\n",
      " [1948.]\n",
      " [1952.]\n",
      " [1956.]\n",
      " [1960.]\n",
      " [1964.]\n",
      " [1968.]\n",
      " [1972.]\n",
      " [1976.]\n",
      " [1980.]\n",
      " [1984.]\n",
      " [1988.]\n",
      " [1992.]\n",
      " [1996.]\n",
      " [2000.]\n",
      " [2004.]\n",
      " [2008.]\n",
      " [2012.]]\n",
      "[[4.47083333]\n",
      " [4.46472926]\n",
      " [5.22208333]\n",
      " [4.15467867]\n",
      " [3.90331675]\n",
      " [3.56951267]\n",
      " [3.82454477]\n",
      " [3.62483707]\n",
      " [3.59284275]\n",
      " [3.53880792]\n",
      " [3.67010309]\n",
      " [3.39029111]\n",
      " [3.43642612]\n",
      " [3.20583007]\n",
      " [3.13275665]\n",
      " [3.32819844]\n",
      " [3.13583758]\n",
      " [3.0789588 ]\n",
      " [3.10581822]\n",
      " [3.06552909]\n",
      " [3.09357349]\n",
      " [3.16111704]\n",
      " [3.14255244]\n",
      " [3.08527867]\n",
      " [3.10265829]\n",
      " [2.99877553]\n",
      " [3.03392977]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that they are not `pandas` data frames for this example, they are just arrays of dimensionality $n\\times 1$, where $n$ is the number of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this lab is to have you coding linear regression in python. We will do it in two ways, once using iterative updates (coordinate ascent) and then using linear algebra. The linear algebra approach will not only work much better, it is easy to extend to multiple input linear regression and *non-linear* regression using basis functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Data\n",
    "\n",
    "You can make a plot of $y$ vs $x$ with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'pace in min/km')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import pylab as plt\n",
    "\n",
    "plt.plot(x, y, 'rx')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('pace in min/km')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood: Iterative Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take the maximum likelihood approach we derived in the lecture to fit a line, $y_i=mx_i + c$, to the data you've plotted. We are trying to minimize the error function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E(m, c) =  \\sum_{i=1}^n(y_i-mx_i-c)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with respect to $m$, $c$ and $\\sigma^2$. We can start with an initial guess for $m$, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -0.4\n",
    "c = 80 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the maximum likelihood update to find an estimate for the offset, $c$.\n",
    "\n",
    "### Coordinate Descent\n",
    "\n",
    "In the movie recommender system example, we minimised the objective function by steepest descent based gradient methods. Our updates required us to compute the gradient at the position we were located, then to update the gradient according to the direction of steepest descent. This time, we will take another approach. It is known as *coordinate descent*. In coordinate descent, we choose to move one parameter at a time. Ideally, we design an algorithm that at each step moves the parameter to its minimum value. At each step we choose to move the individual parameter to its minimum.\n",
    "\n",
    "To find the minimum, we look for the point in the curve where the gradient is zero. This can be found by taking the gradient of $E(m,c)$ with respect to the parameter. \n",
    "\n",
    "#### Update for Offset\n",
    "\n",
    "Let's consider the parameter $c$ first. The gradient goes nicely through the summation operator, and we obtain\n",
    "$$\n",
    "\\frac{\\text{d}E(m,c)}{\\text{d}c} = -\\sum_{i=1}^n 2(y_i-mx_i-c).\n",
    "$$\n",
    "Now we want the point that is a minimum. A minimum is an example of a [*stationary point*](http://en.wikipedia.org/wiki/Stationary_point), the stationary points are those points of the function where the gradient is zero. They are found by solving the equation for $\\frac{\\text{d}E(m,c)}{\\text{d}c} = 0$. Substituting in to our gradient, we can obtain the following equation, \n",
    "$$\n",
    "0 = -\\sum_{i=1}^n 2(y_i-mx_i-c)\n",
    "$$\n",
    "which can be reorganised as follows,\n",
    "$$\n",
    "c^* = \\frac{\\sum_{i=1}^n(y_i-m^*x_i)}{n}.\n",
    "$$\n",
    "The fact that the stationary point is easily extracted in this manner implies that the solution is *unique*. There is only one stationary point for this system. Traditionally when trying to determine the type of stationary point we have encountered we now compute the *second derivative*,\n",
    "$$\n",
    "\\frac{\\text{d}^2E(m,c)}{\\text{d}c^2} = 2n.\n",
    "$$\n",
    "The second derivative is positive, which in turn implies that we have found a minimum of the function. This means that setting $c$ in this way will take us to the lowest point along that axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786.0197711453593\n"
     ]
    }
   ],
   "source": [
    "# set c to the minimum\n",
    "c = (y - m*x).mean()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update for Slope\n",
    "\n",
    "Now we have the offset set to the minimum value, in coordinate descent, the next step is to optimise another parameter. Only one further parameter remains. That is the slope of the system. \n",
    "\n",
    "Now we can turn our attention to the slope. We once again peform the same set of computations to find the minima. We end up with an update equation of the following form.\n",
    "\n",
    "$$m^* = \\frac{\\sum_{i=1}^n (y_i - c)x_i}{\\sum_{i=1}^n x_i^2}$$\n",
    "\n",
    "Communication of mathematics in data science is an essential skill, in a moment, you will be asked to rederive the equation above. Before we do that, however, we will briefly review how to write mathematics in the notebook.\n",
    "\n",
    "### $\\LaTeX$ for Maths\n",
    "\n",
    "These cells use [Markdown format](http://en.wikipedia.org/wiki/Markdown). You can include maths in your markdown using [$\\LaTeX$ syntax](http://en.wikipedia.org/wiki/LaTeX), all you have to do is write your answer inside dollar signs, as follows:\n",
    "\n",
    "To write a fraction, we write `$\\frac{a}{b}$`, and it will display like this $\\frac{a}{b}$. To write a subscript we write `$a_b$` which will appear as $a_b$. To write a superscript (for example in a polynomial) we write `$a^b$` which will appear as $a^b$. There are lots of other macros as well, for example we can do greek letters such as `$\\alpha, \\beta, \\gamma$` rendering as $\\alpha, \\beta, \\gamma$. And we can do sum and intergral signs as `$\\sum \\int \\int$`.\n",
    "\n",
    "You can combine many of these operations together for composing expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 1 \n",
    "\n",
    "Convert the following python code expressions into $\\LaTeX$j, writing your answers below. In each case write your answer as a single equality (i.e. your maths should only contain one expression, not several lines of expressions). For the purposes of your $\\LaTeX$ please assume that `x` and `w` are $n$ dimensional vectors. \n",
    "\n",
    "(a) \n",
    "``` python\n",
    "f = x.sum()\n",
    "```\n",
    "\n",
    "(b) \n",
    "``` python \n",
    "m = x.mean()\n",
    "```\n",
    "\n",
    "(c) \n",
    "``` python\n",
    "g = (x*w).sum()\n",
    "```\n",
    "\n",
    "*15 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 Answer\n",
    "\n",
    "(a) $$f = \\sum_{i=1}^n x_i$$\n",
    "(b) $$m = \\frac{\\sum_{i=1}^n x_i}{n}$$\n",
    "(c) $$g = \\sum_{i=1}^n x_i  w_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient With Respect to the Slope\n",
    "Now that you've had a little training in writing maths with $\\LaTeX$, we will be able to use it to answer questions. The next thing we are going to do is a little differentiation practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 2\n",
    "\n",
    "Derive the the gradient of the objective function with respect to the slope, $m$. Rearrange it to show that the update equation written above does find the stationary points of the objective function. By computing its derivative show that it's a minimum.\n",
    "\n",
    "*20 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 Answer\n",
    "\n",
    "The gradient of the objective function with respect to mgoes nicely through the summation operator, and we obtain\n",
    "$$\n",
    "\\frac{\\text{d}E(m,c)}{\\text{d}m} = -2\\sum_{i=1}^n x_i (y_i-mx_i-c).\n",
    "$$\n",
    "In order to compute the stationary point we should find the points where the gradient is zero, i.e. $\\frac{\\text{d}E(m,c)}{\\text{d}m} = 0$. Thus, we obtain the following equation:\n",
    "$$\n",
    "0 = -2\\sum_{i=1}^n x_i(y_i-m^*x_i-c)\n",
    "$$\n",
    "which can be reorganised as:\n",
    "$$\n",
    "\\sum_{i=1}^n x_i(y_i-c) - \\sum_{i=1}^n m^* x_i^2 = 0 \n",
    "$$\n",
    "$$\n",
    "m^*\\sum_{i=1}^n x_i^2 = \\sum_{i=1}^n x_i(y_i-c)\n",
    "$$\n",
    "\n",
    "$$\n",
    "m^* = \\frac{\\sum_{i=1}^n (y_i - c)x_i}{\\sum_{i=1}^n x_i^2}.\n",
    "$$\n",
    "Now, to understand if this stationary point is minimum or maximum we have to compute the second derivative. If the second derivative is positive, then the stationary point is going to be minimum, otherwise it is going to be maximum.\n",
    "The second derivtive is:\n",
    "$$\n",
    "\\frac{\\text{d}^2E(m,c)}{\\text{d}m^2} = 2\\sum_{i=1}^n x_i^2.\n",
    "$$\n",
    "The second derivative is positive, since the sum of squared terms is always positive, so the computed $m^*$ is a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3998724072997095\n"
     ]
    }
   ],
   "source": [
    "m = ((y - c)*x).sum()/(x**2).sum()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at how good our fit is by computing the prediction across the input space. First create a vector of 'test points',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_test = np.linspace(1890, 2020, 130)[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this vector to compute some test predictions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test = m*x_test + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot those test predictions with a blue line on the same plot as the data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x113698978>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_test, f_test, 'b-')\n",
    "plt.plot(x, y, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit isn't very good, we need to iterate between these parameter updates in a loop to improve the fit, we have to do this several times,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3987259642505432\n",
      "783.5273797273478\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(10):\n",
    "    m = ((y - c)*x).sum()/(x*x).sum()\n",
    "    c = (y-m*x).sum()/y.shape[0]\n",
    "print(m)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's try plotting the result again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11357e208>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_test = m*x_test + c\n",
    "plt.plot(x_test, f_test, 'b-')\n",
    "plt.plot(x, y, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we need more iterations than 10! In the next question you will add more iterations and report on the error as optimisation proceeds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 3\n",
    "\n",
    "There is a problem here, we seem to need many interations to get to a good solution. Let's explore what's going on. Write code which alternates between updates of `c` and `m`. Include the following features in your code.\n",
    "\n",
    "(a) Initialise with `m=-0.4` and `c=80`.\n",
    "(b) Every 10 iterations compute the value of the objective function for the training data and print it to the screen (you'll find hints on this in the lab from last week.\n",
    "(c) Cause the code to stop running when the error change over less than 10 iterations is smaller than $1\\times10^{-4}$. This is known as a stopping criterion.\n",
    "\n",
    "Why do we need so many iterations to get to the solution?\n",
    "\n",
    "*25 marks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 Objective Function: 25.082467969685627\n",
      "Iteration: 20 Objective Function: 24.930615384247915\n",
      "Iteration: 30 Objective Function: 24.779760925570276\n",
      "Iteration: 40 Objective Function: 24.629898032967365\n",
      "Iteration: 50 Objective Function: 24.481020188877213\n",
      "Iteration: 60 Objective Function: 24.33312091857767\n",
      "Iteration: 70 Objective Function: 24.1861937899053\n",
      "Iteration: 80 Objective Function: 24.040232412974916\n",
      "Iteration: 90 Objective Function: 23.895230439901937\n",
      "Iteration: 100 Objective Function: 23.751181564526696\n",
      "Iteration: 110 Objective Function: 23.608079522139967\n",
      "Iteration: 120 Objective Function: 23.465918089210145\n",
      "Iteration: 130 Objective Function: 23.324691083113112\n",
      "Iteration: 140 Objective Function: 23.18439236186285\n",
      "Iteration: 150 Objective Function: 23.045015823845084\n",
      "Iteration: 160 Objective Function: 22.906555407550893\n",
      "Iteration: 170 Objective Function: 22.769005091314067\n",
      "Iteration: 180 Objective Function: 22.632358893048487\n",
      "Iteration: 190 Objective Function: 22.496610869988505\n",
      "Iteration: 200 Objective Function: 22.361755118430246\n",
      "Iteration: 210 Objective Function: 22.227785773474658\n",
      "Iteration: 220 Objective Function: 22.09469700877289\n",
      "Iteration: 230 Objective Function: 21.9624830362726\n",
      "Iteration: 240 Objective Function: 21.831138105966286\n",
      "Iteration: 250 Objective Function: 21.700656505641142\n",
      "Iteration: 260 Objective Function: 21.57103256063089\n",
      "Iteration: 270 Objective Function: 21.442260633568683\n",
      "Iteration: 280 Objective Function: 21.314335124142193\n",
      "Iteration: 290 Objective Function: 21.187250468849747\n",
      "Iteration: 300 Objective Function: 21.061001140758997\n",
      "Iteration: 310 Objective Function: 20.93558164926571\n",
      "Iteration: 320 Objective Function: 20.81098653985524\n",
      "Iteration: 330 Objective Function: 20.687210393865918\n",
      "Iteration: 340 Objective Function: 20.564247828252682\n",
      "Iteration: 350 Objective Function: 20.44209349535313\n",
      "Iteration: 360 Objective Function: 20.320742082655347\n",
      "Iteration: 370 Objective Function: 20.200188312566116\n",
      "Iteration: 380 Objective Function: 20.08042694218221\n",
      "Iteration: 390 Objective Function: 19.96145276306188\n",
      "Iteration: 400 Objective Function: 19.84326060099832\n",
      "Iteration: 410 Objective Function: 19.725845315794984\n",
      "Iteration: 420 Objective Function: 19.609201801041582\n",
      "Iteration: 430 Objective Function: 19.49332498389235\n",
      "Iteration: 440 Objective Function: 19.378209824845733\n",
      "Iteration: 450 Objective Function: 19.26385131752414\n",
      "Iteration: 460 Objective Function: 19.150244488457375\n",
      "Iteration: 470 Objective Function: 19.037384396865363\n",
      "Iteration: 480 Objective Function: 18.925266134444264\n",
      "Iteration: 490 Objective Function: 18.81388482515247\n",
      "Iteration: 500 Objective Function: 18.703235624998264\n",
      "Iteration: 510 Objective Function: 18.59331372182963\n",
      "Iteration: 520 Objective Function: 18.48411433512495\n",
      "Iteration: 530 Objective Function: 18.375632715784853\n",
      "Iteration: 540 Objective Function: 18.267864145925703\n",
      "Iteration: 550 Objective Function: 18.160803938674682\n",
      "Iteration: 560 Objective Function: 18.054447437965667\n",
      "Iteration: 570 Objective Function: 17.94879001833686\n",
      "Iteration: 580 Objective Function: 17.84382708472978\n",
      "Iteration: 590 Objective Function: 17.73955407228874\n",
      "Iteration: 600 Objective Function: 17.635966446163515\n",
      "Iteration: 610 Objective Function: 17.533059701310993\n",
      "Iteration: 620 Objective Function: 17.43082936229999\n",
      "Iteration: 630 Objective Function: 17.329270983116036\n",
      "Iteration: 640 Objective Function: 17.22838014696849\n",
      "Iteration: 650 Objective Function: 17.128152466098243\n",
      "Iteration: 660 Objective Function: 17.02858358158688\n",
      "Iteration: 670 Objective Function: 16.92966916316712\n",
      "Iteration: 680 Objective Function: 16.83140490903456\n",
      "Iteration: 690 Objective Function: 16.73378654566073\n",
      "Iteration: 700 Objective Function: 16.636809827606704\n",
      "Iteration: 710 Objective Function: 16.540470537339054\n",
      "Iteration: 720 Objective Function: 16.44476448504612\n",
      "Iteration: 730 Objective Function: 16.34968750845602\n",
      "Iteration: 740 Objective Function: 16.255235472654988\n",
      "Iteration: 750 Objective Function: 16.161404269908722\n",
      "Iteration: 760 Objective Function: 16.068189819482583\n",
      "Iteration: 770 Objective Function: 15.975588067464702\n",
      "Iteration: 780 Objective Function: 15.88359498658962\n",
      "Iteration: 790 Objective Function: 15.792206576063029\n",
      "Iteration: 800 Objective Function: 15.701418861387994\n",
      "Iteration: 810 Objective Function: 15.611227894191574\n",
      "Iteration: 820 Objective Function: 15.521629752053807\n",
      "Iteration: 830 Objective Function: 15.432620538336854\n",
      "Iteration: 840 Objective Function: 15.34419638201511\n",
      "Iteration: 850 Objective Function: 15.256353437507453\n",
      "Iteration: 860 Objective Function: 15.16908788450973\n",
      "Iteration: 870 Objective Function: 15.082395927828669\n",
      "Iteration: 880 Objective Function: 14.996273797216672\n",
      "Iteration: 890 Objective Function: 14.910717747208077\n",
      "Iteration: 900 Objective Function: 14.825724056956133\n",
      "Iteration: 910 Objective Function: 14.741289030071297\n",
      "Iteration: 920 Objective Function: 14.657408994460267\n",
      "Iteration: 930 Objective Function: 14.574080302166312\n",
      "Iteration: 940 Objective Function: 14.491299329211001\n",
      "Iteration: 950 Objective Function: 14.409062475436135\n",
      "Iteration: 960 Objective Function: 14.327366164347202\n",
      "Iteration: 970 Objective Function: 14.24620684295819\n",
      "Iteration: 980 Objective Function: 14.165580981637042\n",
      "Iteration: 990 Objective Function: 14.085485073951364\n",
      "Iteration: 1000 Objective Function: 14.005915636517294\n",
      "Iteration: 1010 Objective Function: 13.92686920884632\n",
      "Iteration: 1020 Objective Function: 13.848342353196774\n",
      "Iteration: 1030 Objective Function: 13.770331654422494\n",
      "Iteration: 1040 Objective Function: 13.692833719825344\n",
      "Iteration: 1050 Objective Function: 13.615845179007332\n",
      "Iteration: 1060 Objective Function: 13.539362683724121\n",
      "Iteration: 1070 Objective Function: 13.463382907739291\n",
      "Iteration: 1080 Objective Function: 13.387902546679923\n",
      "Iteration: 1090 Objective Function: 13.31291831789262\n",
      "Iteration: 1100 Objective Function: 13.238426960300913\n",
      "Iteration: 1110 Objective Function: 13.1644252342633\n",
      "Iteration: 1120 Objective Function: 13.090909921432457\n",
      "Iteration: 1130 Objective Function: 13.017877824615491\n",
      "Iteration: 1140 Objective Function: 12.945325767634106\n",
      "Iteration: 1150 Objective Function: 12.873250595187626\n",
      "Iteration: 1160 Objective Function: 12.801649172714823\n",
      "Iteration: 1170 Objective Function: 12.730518386257941\n",
      "Iteration: 1180 Objective Function: 12.65985514232745\n",
      "Iteration: 1190 Objective Function: 12.58965636776718\n",
      "Iteration: 1200 Objective Function: 12.519919009620653\n",
      "Iteration: 1210 Objective Function: 12.450640034998862\n",
      "Iteration: 1220 Objective Function: 12.381816430947634\n",
      "Iteration: 1230 Objective Function: 12.31344520431715\n",
      "Iteration: 1240 Objective Function: 12.245523381631338\n",
      "Iteration: 1250 Objective Function: 12.178048008959063\n",
      "Iteration: 1260 Objective Function: 12.111016151785106\n",
      "Iteration: 1270 Objective Function: 12.044424894883042\n",
      "Iteration: 1280 Objective Function: 11.97827134218799\n",
      "Iteration: 1290 Objective Function: 11.912552616671086\n",
      "Iteration: 1300 Objective Function: 11.847265860214033\n",
      "Iteration: 1310 Objective Function: 11.782408233485052\n",
      "Iteration: 1320 Objective Function: 11.717976915815223\n",
      "Iteration: 1330 Objective Function: 11.653969105075895\n",
      "Iteration: 1340 Objective Function: 11.590382017556886\n",
      "Iteration: 1350 Objective Function: 11.527212887845206\n",
      "Iteration: 1360 Objective Function: 11.46445896870494\n",
      "Iteration: 1370 Objective Function: 11.402117530957733\n",
      "Iteration: 1380 Objective Function: 11.340185863364301\n",
      "Iteration: 1390 Objective Function: 11.278661272506138\n",
      "Iteration: 1400 Objective Function: 11.217541082668546\n",
      "Iteration: 1410 Objective Function: 11.156822635724469\n",
      "Iteration: 1420 Objective Function: 11.096503291018546\n",
      "Iteration: 1430 Objective Function: 11.036580425252534\n",
      "Iteration: 1440 Objective Function: 10.977051432371148\n",
      "Iteration: 1450 Objective Function: 10.917913723448601\n",
      "Iteration: 1460 Objective Function: 10.85916472657621\n",
      "Iteration: 1470 Objective Function: 10.800801886750358\n",
      "Iteration: 1480 Objective Function: 10.742822665761528\n",
      "Iteration: 1490 Objective Function: 10.685224542083802\n",
      "Iteration: 1500 Objective Function: 10.628005010765259\n",
      "Iteration: 1510 Objective Function: 10.57116158331904\n",
      "Iteration: 1520 Objective Function: 10.514691787615089\n",
      "Iteration: 1530 Objective Function: 10.45859316777269\n",
      "Iteration: 1540 Objective Function: 10.402863284053558\n",
      "Iteration: 1550 Objective Function: 10.347499712755841\n",
      "Iteration: 1560 Objective Function: 10.292500046108767\n",
      "Iteration: 1570 Objective Function: 10.237861892167652\n",
      "Iteration: 1580 Objective Function: 10.183582874710169\n",
      "Iteration: 1590 Objective Function: 10.12966063313296\n",
      "Iteration: 1600 Objective Function: 10.076092822348734\n",
      "Iteration: 1610 Objective Function: 10.022877112684544\n",
      "Iteration: 1620 Objective Function: 9.97001118978055\n",
      "Iteration: 1630 Objective Function: 9.917492754488855\n",
      "Iteration: 1640 Objective Function: 9.865319522774097\n",
      "Iteration: 1650 Objective Function: 9.813489225613806\n",
      "Iteration: 1660 Objective Function: 9.76199960889982\n",
      "Iteration: 1670 Objective Function: 9.71084843334017\n",
      "Iteration: 1680 Objective Function: 9.660033474361777\n",
      "Iteration: 1690 Objective Function: 9.609552522013733\n",
      "Iteration: 1700 Objective Function: 9.559403380871025\n",
      "Iteration: 1710 Objective Function: 9.50958386993925\n",
      "Iteration: 1720 Objective Function: 9.460091822559614\n",
      "Iteration: 1730 Objective Function: 9.410925086314876\n",
      "Iteration: 1740 Objective Function: 9.362081522935462\n",
      "Iteration: 1750 Objective Function: 9.313559008206807\n",
      "Iteration: 1760 Objective Function: 9.265355431876678\n",
      "Iteration: 1770 Objective Function: 9.217468697563628\n",
      "Iteration: 1780 Objective Function: 9.169896722665642\n",
      "Iteration: 1790 Objective Function: 9.122637438269647\n",
      "Iteration: 1800 Objective Function: 9.075688789061601\n",
      "Iteration: 1810 Objective Function: 9.029048733236962\n",
      "Iteration: 1820 Objective Function: 8.982715242412059\n",
      "Iteration: 1830 Objective Function: 8.936686301535657\n",
      "Iteration: 1840 Objective Function: 8.890959908801543\n",
      "Iteration: 1850 Objective Function: 8.845534075561329\n",
      "Iteration: 1860 Objective Function: 8.800406826238007\n",
      "Iteration: 1870 Objective Function: 8.755576198240101\n",
      "Iteration: 1880 Objective Function: 8.711040241876148\n",
      "Iteration: 1890 Objective Function: 8.66679702027009\n",
      "Iteration: 1900 Objective Function: 8.622844609276893\n",
      "Iteration: 1910 Objective Function: 8.579181097398953\n",
      "Iteration: 1920 Objective Function: 8.535804585702914\n",
      "Iteration: 1930 Objective Function: 8.492713187737042\n",
      "Iteration: 1940 Objective Function: 8.449905029449516\n",
      "Iteration: 1950 Objective Function: 8.407378249106246\n",
      "Iteration: 1960 Objective Function: 8.365130997210624\n",
      "Iteration: 1970 Objective Function: 8.323161436422723\n",
      "Iteration: 1980 Objective Function: 8.281467741479387\n",
      "Iteration: 1990 Objective Function: 8.240048099114901\n",
      "Iteration: 2000 Objective Function: 8.198900707982226\n",
      "Iteration: 2010 Objective Function: 8.158023778574488\n",
      "Iteration: 2020 Objective Function: 8.11741553314729\n",
      "Iteration: 2030 Objective Function: 8.077074205641287\n",
      "Iteration: 2040 Objective Function: 8.036998041605544\n",
      "Iteration: 2050 Objective Function: 7.9971852981210425\n",
      "Iteration: 2060 Objective Function: 7.957634243725028\n",
      "Iteration: 2070 Objective Function: 7.918343158335571\n",
      "Iteration: 2080 Objective Function: 7.8793103331768695\n",
      "Iteration: 2090 Objective Function: 7.840534070704923\n",
      "Iteration: 2100 Objective Function: 7.802012684533652\n",
      "Iteration: 2110 Objective Function: 7.763744499361626\n",
      "Iteration: 2120 Objective Function: 7.72572785089918\n",
      "Iteration: 2130 Objective Function: 7.687961085795962\n",
      "Iteration: 2140 Objective Function: 7.6504425615691245\n",
      "Iteration: 2150 Objective Function: 7.613170646531842\n",
      "Iteration: 2160 Objective Function: 7.57614371972236\n",
      "Iteration: 2170 Objective Function: 7.53936017083357\n",
      "Iteration: 2180 Objective Function: 7.502818400142811\n",
      "Iteration: 2190 Objective Function: 7.46651681844243\n",
      "Iteration: 2200 Objective Function: 7.430453846970678\n",
      "Iteration: 2210 Objective Function: 7.3946279173429135\n",
      "Iteration: 2220 Objective Function: 7.3590374714836555\n",
      "Iteration: 2230 Objective Function: 7.323680961558414\n",
      "Iteration: 2240 Objective Function: 7.288556849906775\n",
      "Iteration: 2250 Objective Function: 7.253663608975337\n",
      "Iteration: 2260 Objective Function: 7.218999721251255\n",
      "Iteration: 2270 Objective Function: 7.184563679196337\n",
      "Iteration: 2280 Objective Function: 7.150353985181471\n",
      "Iteration: 2290 Objective Function: 7.116369151421368\n",
      "Iteration: 2300 Objective Function: 7.082607699910001\n",
      "Iteration: 2310 Objective Function: 7.049068162356226\n",
      "Iteration: 2320 Objective Function: 7.015749080120113\n",
      "Iteration: 2330 Objective Function: 6.982649004149151\n",
      "Iteration: 2340 Objective Function: 6.949766494915691\n",
      "Iteration: 2350 Objective Function: 6.917100122353857\n",
      "Iteration: 2360 Objective Function: 6.884648465797808\n",
      "Iteration: 2370 Objective Function: 6.852410113919589\n",
      "Iteration: 2380 Objective Function: 6.820383664667987\n",
      "Iteration: 2390 Objective Function: 6.788567725207388\n",
      "Iteration: 2400 Objective Function: 6.756960911857343\n",
      "Iteration: 2410 Objective Function: 6.725561850032331\n",
      "Iteration: 2420 Objective Function: 6.694369174181958\n",
      "Iteration: 2430 Objective Function: 6.663381527731615\n",
      "Iteration: 2440 Objective Function: 6.63259756302342\n",
      "Iteration: 2450 Objective Function: 6.6020159412576644\n",
      "Iteration: 2460 Objective Function: 6.571635332434569\n",
      "Iteration: 2470 Objective Function: 6.541454415296434\n",
      "Iteration: 2480 Objective Function: 6.511471877270204\n",
      "Iteration: 2490 Objective Function: 6.481686414410338\n",
      "Iteration: 2500 Objective Function: 6.452096731342142\n",
      "Iteration: 2510 Objective Function: 6.42270154120537\n",
      "Iteration: 2520 Objective Function: 6.393499565598384\n",
      "Iteration: 2530 Objective Function: 6.364489534522461\n",
      "Iteration: 2540 Objective Function: 6.335670186326532\n",
      "Iteration: 2550 Objective Function: 6.307040267652382\n",
      "Iteration: 2560 Objective Function: 6.27859853338011\n",
      "Iteration: 2570 Objective Function: 6.250343746574049\n",
      "Iteration: 2580 Objective Function: 6.222274678428769\n",
      "Iteration: 2590 Objective Function: 6.194390108215956\n",
      "Iteration: 2600 Objective Function: 6.166688823230983\n",
      "Iteration: 2610 Objective Function: 6.139169618740371\n",
      "Iteration: 2620 Objective Function: 6.111831297929419\n",
      "Iteration: 2630 Objective Function: 6.084672671850017\n",
      "Iteration: 2640 Objective Function: 6.057692559369014\n",
      "Iteration: 2650 Objective Function: 6.0308897871168945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2660 Objective Function: 6.004263189436669\n",
      "Iteration: 2670 Objective Function: 5.977811608333212\n",
      "Iteration: 2680 Objective Function: 5.951533893422807\n",
      "Iteration: 2690 Objective Function: 5.92542890188339\n",
      "Iteration: 2700 Objective Function: 5.899495498404523\n",
      "Iteration: 2710 Objective Function: 5.873732555138225\n",
      "Iteration: 2720 Objective Function: 5.848138951649799\n",
      "Iteration: 2730 Objective Function: 5.822713574869245\n",
      "Iteration: 2740 Objective Function: 5.797455319042715\n",
      "Iteration: 2750 Objective Function: 5.772363085684482\n",
      "Iteration: 2760 Objective Function: 5.747435783529167\n",
      "Iteration: 2770 Objective Function: 5.722672328484321\n",
      "Iteration: 2780 Objective Function: 5.698071643583172\n",
      "Iteration: 2790 Objective Function: 5.673632658937821\n",
      "Iteration: 2800 Objective Function: 5.649354311692848\n",
      "Iteration: 2810 Objective Function: 5.62523554597888\n",
      "Iteration: 2820 Objective Function: 5.601275312866877\n",
      "Iteration: 2830 Objective Function: 5.57747257032228\n",
      "Iteration: 2840 Objective Function: 5.5538262831599265\n",
      "Iteration: 2850 Objective Function: 5.530335422998814\n",
      "Iteration: 2860 Objective Function: 5.5069989682176335\n",
      "Iteration: 2870 Objective Function: 5.483815903910088\n",
      "Iteration: 2880 Objective Function: 5.460785221840849\n",
      "Iteration: 2890 Objective Function: 5.437905920401735\n",
      "Iteration: 2900 Objective Function: 5.415177004568233\n",
      "Iteration: 2910 Objective Function: 5.392597485855955\n",
      "Iteration: 2920 Objective Function: 5.370166382277976\n",
      "Iteration: 2930 Objective Function: 5.347882718301829\n",
      "Iteration: 2940 Objective Function: 5.325745524807299\n",
      "Iteration: 2950 Objective Function: 5.303753839044224\n",
      "Iteration: 2960 Objective Function: 5.281906704590554\n",
      "Iteration: 2970 Objective Function: 5.260203171310736\n",
      "Iteration: 2980 Objective Function: 5.23864229531462\n",
      "Iteration: 2990 Objective Function: 5.217223138916099\n",
      "Iteration: 3000 Objective Function: 5.1959447705925115\n",
      "Iteration: 3010 Objective Function: 5.17480626494409\n",
      "Iteration: 3020 Objective Function: 5.153806702653747\n",
      "Iteration: 3030 Objective Function: 5.132945170447091\n",
      "Iteration: 3040 Objective Function: 5.112220761052573\n",
      "Iteration: 3050 Objective Function: 5.091632573162223\n",
      "Iteration: 3060 Objective Function: 5.071179711392442\n",
      "Iteration: 3070 Objective Function: 5.0508612862447775\n",
      "Iteration: 3080 Objective Function: 5.030676414067611\n",
      "Iteration: 3090 Objective Function: 5.01062421701748\n",
      "Iteration: 3100 Objective Function: 4.9907038230210725\n",
      "Iteration: 3110 Objective Function: 4.9709143657371495\n",
      "Iteration: 3120 Objective Function: 4.951254984518932\n",
      "Iteration: 3130 Objective Function: 4.9317248243767\n",
      "Iteration: 3140 Objective Function: 4.912323035940519\n",
      "Iteration: 3150 Objective Function: 4.893048775423446\n",
      "Iteration: 3160 Objective Function: 4.87390120458472\n",
      "Iteration: 3170 Objective Function: 4.854879490693271\n",
      "Iteration: 3180 Objective Function: 4.8359828064916375\n",
      "Iteration: 3190 Objective Function: 4.817210330159946\n",
      "Iteration: 3200 Objective Function: 4.798561245280068\n",
      "Iteration: 3210 Objective Function: 4.780034740800229\n",
      "Iteration: 3220 Objective Function: 4.7616300109996645\n",
      "Iteration: 3230 Objective Function: 4.743346255453673\n",
      "Iteration: 3240 Objective Function: 4.725182678998674\n",
      "Iteration: 3250 Objective Function: 4.707138491697745\n",
      "Iteration: 3260 Objective Function: 4.689212908806179\n",
      "Iteration: 3270 Objective Function: 4.671405150737424\n",
      "Iteration: 3280 Objective Function: 4.6537144430291555\n",
      "Iteration: 3290 Objective Function: 4.636140016309563\n",
      "Iteration: 3300 Objective Function: 4.618681106263914\n",
      "Iteration: 3310 Objective Function: 4.601336953601322\n",
      "Iteration: 3320 Objective Function: 4.584106804021764\n",
      "Iteration: 3330 Objective Function: 4.566989908183164\n",
      "Iteration: 3340 Objective Function: 4.549985521668894\n",
      "Iteration: 3350 Objective Function: 4.533092904955381\n",
      "Iteration: 3360 Objective Function: 4.5163113233799175\n",
      "Iteration: 3370 Objective Function: 4.4996400471087625\n",
      "Iteration: 3380 Objective Function: 4.48307835110533\n",
      "Iteration: 3390 Objective Function: 4.466625515098759\n",
      "Iteration: 3400 Objective Function: 4.450280823552477\n",
      "Iteration: 3410 Objective Function: 4.4340435656331705\n",
      "Iteration: 3420 Objective Function: 4.417913035179785\n",
      "Iteration: 3430 Objective Function: 4.401888530672912\n",
      "Iteration: 3440 Objective Function: 4.385969355204175\n",
      "Iteration: 3450 Objective Function: 4.370154816446009\n",
      "Iteration: 3460 Objective Function: 4.354444226621561\n",
      "Iteration: 3470 Objective Function: 4.338836902474626\n",
      "Iteration: 3480 Objective Function: 4.323332165240088\n",
      "Iteration: 3490 Objective Function: 4.307929340614418\n",
      "Iteration: 3500 Objective Function: 4.292627758726177\n",
      "Iteration: 3510 Objective Function: 4.27742675410711\n",
      "Iteration: 3520 Objective Function: 4.26232566566292\n",
      "Iteration: 3530 Objective Function: 4.247323836644847\n",
      "Iteration: 3540 Objective Function: 4.232420614620848\n",
      "Iteration: 3550 Objective Function: 4.217615351447324\n",
      "Iteration: 3560 Objective Function: 4.202907403240969\n",
      "Iteration: 3570 Objective Function: 4.188296130350636\n",
      "Iteration: 3580 Objective Function: 4.173780897329721\n",
      "Iteration: 3590 Objective Function: 4.159361072908279\n",
      "Iteration: 3600 Objective Function: 4.145036029965777\n",
      "Iteration: 3610 Objective Function: 4.130805145503727\n",
      "Iteration: 3620 Objective Function: 4.11666780061865\n",
      "Iteration: 3630 Objective Function: 4.102623380475024\n",
      "Iteration: 3640 Objective Function: 4.088671274278779\n",
      "Iteration: 3650 Objective Function: 4.0748108752504315\n",
      "Iteration: 3660 Objective Function: 4.061041580599012\n",
      "Iteration: 3670 Objective Function: 4.0473627914955275\n",
      "Iteration: 3680 Objective Function: 4.033773913047255\n",
      "Iteration: 3690 Objective Function: 4.020274354271617\n",
      "Iteration: 3700 Objective Function: 4.006863528070533\n",
      "Iteration: 3710 Objective Function: 3.9935408512050112\n",
      "Iteration: 3720 Objective Function: 3.980305744269596\n",
      "Iteration: 3730 Objective Function: 3.9671576316673174\n",
      "Iteration: 3740 Objective Function: 3.954095941584571\n",
      "Iteration: 3750 Objective Function: 3.9411201059663146\n",
      "Iteration: 3760 Objective Function: 3.928229560491307\n",
      "Iteration: 3770 Objective Function: 3.91542374454756\n",
      "Iteration: 3780 Objective Function: 3.902702101208106\n",
      "Iteration: 3790 Objective Function: 3.890064077206497\n",
      "Iteration: 3800 Objective Function: 3.877509122913021\n",
      "Iteration: 3810 Objective Function: 3.8650366923106283\n",
      "Iteration: 3820 Objective Function: 3.852646242971258\n",
      "Iteration: 3830 Objective Function: 3.8403372360322185\n",
      "Iteration: 3840 Objective Function: 3.8281091361727735\n",
      "Iteration: 3850 Objective Function: 3.815961411590798\n",
      "Iteration: 3860 Objective Function: 3.8038935339798052\n",
      "Iteration: 3870 Objective Function: 3.7919049785057783\n",
      "Iteration: 3880 Objective Function: 3.779995223784439\n",
      "Iteration: 3890 Objective Function: 3.768163751858607\n",
      "Iteration: 3900 Objective Function: 3.7564100481755913\n",
      "Iteration: 3910 Objective Function: 3.7447336015649517\n",
      "Iteration: 3920 Objective Function: 3.7331339042160243\n",
      "Iteration: 3930 Objective Function: 3.7216104516560664\n",
      "Iteration: 3940 Objective Function: 3.710162742728216\n",
      "Iteration: 3950 Objective Function: 3.698790279569742\n",
      "Iteration: 3960 Objective Function: 3.687492567590359\n",
      "Iteration: 3970 Objective Function: 3.6762691154506792\n",
      "Iteration: 3980 Objective Function: 3.665119435040909\n",
      "Iteration: 3990 Objective Function: 3.6540430414596328\n",
      "Iteration: 4000 Objective Function: 3.6430394529926335\n",
      "Iteration: 4010 Objective Function: 3.6321081910920294\n",
      "Iteration: 4020 Objective Function: 3.6212487803554905\n",
      "Iteration: 4030 Objective Function: 3.61046074850537\n",
      "Iteration: 4040 Objective Function: 3.5997436263684492\n",
      "Iteration: 4050 Objective Function: 3.5890969478552597\n",
      "Iteration: 4060 Objective Function: 3.5785202499400532\n",
      "Iteration: 4070 Objective Function: 3.568013072640447\n",
      "Iteration: 4080 Objective Function: 3.5575749589975683\n",
      "Iteration: 4090 Objective Function: 3.5472054550561385\n",
      "Iteration: 4100 Objective Function: 3.5369041098447442\n",
      "Iteration: 4110 Objective Function: 3.526670475356139\n",
      "Iteration: 4120 Objective Function: 3.5165041065278677\n",
      "Iteration: 4130 Objective Function: 3.5064045612229116\n",
      "Iteration: 4140 Objective Function: 3.496371400210351\n",
      "Iteration: 4150 Objective Function: 3.4864041871463534\n",
      "Iteration: 4160 Objective Function: 3.4765024885551865\n",
      "Iteration: 4170 Objective Function: 3.466665873810308\n",
      "Iteration: 4180 Objective Function: 3.4568939151157814\n",
      "Iteration: 4190 Objective Function: 3.4471861874874685\n",
      "Iteration: 4200 Objective Function: 3.4375422687346884\n",
      "Iteration: 4210 Objective Function: 3.4279617394418294\n",
      "Iteration: 4220 Objective Function: 3.4184441829501093\n",
      "Iteration: 4230 Objective Function: 3.408989185339392\n",
      "Iteration: 4240 Objective Function: 3.399596335410286\n",
      "Iteration: 4250 Objective Function: 3.3902652246661944\n",
      "Iteration: 4260 Objective Function: 3.380995447295579\n",
      "Iteration: 4270 Objective Function: 3.3717866001542793\n",
      "Iteration: 4280 Objective Function: 3.3626382827479944\n",
      "Iteration: 4290 Objective Function: 3.353550097214926\n",
      "Iteration: 4300 Objective Function: 3.344521648308372\n",
      "Iteration: 4310 Objective Function: 3.3355525433796\n",
      "Iteration: 4320 Objective Function: 3.326642392360735\n",
      "Iteration: 4330 Objective Function: 3.3177908077478375\n",
      "Iteration: 4340 Objective Function: 3.3089974045840482\n",
      "Iteration: 4350 Objective Function: 3.3002618004428146\n",
      "Iteration: 4360 Objective Function: 3.2915836154112568\n",
      "Iteration: 4370 Objective Function: 3.2829624720736827\n",
      "Iteration: 4380 Objective Function: 3.274397995495142\n",
      "Iteration: 4390 Objective Function: 3.2658898132051117\n",
      "Iteration: 4400 Objective Function: 3.2574375551813897\n",
      "Iteration: 4410 Objective Function: 3.2490408538338347\n",
      "Iteration: 4420 Objective Function: 3.240699343988532\n",
      "Iteration: 4430 Objective Function: 3.2324126628718344\n",
      "Iteration: 4440 Objective Function: 3.2241804500946096\n",
      "Iteration: 4450 Objective Function: 3.216002347636592\n",
      "Iteration: 4460 Objective Function: 3.2078779998307327\n",
      "Iteration: 4470 Objective Function: 3.1998070533477785\n",
      "Iteration: 4480 Objective Function: 3.1917891571809687\n",
      "Iteration: 4490 Objective Function: 3.1838239626306852\n",
      "Iteration: 4500 Objective Function: 3.1759111232892647\n",
      "Iteration: 4510 Objective Function: 3.16805029502605\n",
      "Iteration: 4520 Objective Function: 3.1602411359722753\n",
      "Iteration: 4530 Objective Function: 3.1524833065063858\n",
      "Iteration: 4540 Objective Function: 3.1447764692390496\n",
      "Iteration: 4550 Objective Function: 3.1371202889986503\n",
      "Iteration: 4560 Objective Function: 3.1295144328166558\n",
      "Iteration: 4570 Objective Function: 3.1219585699131196\n",
      "Iteration: 4580 Objective Function: 3.1144523716823267\n",
      "Iteration: 4590 Objective Function: 3.106995511678466\n",
      "Iteration: 4600 Objective Function: 3.0995876656014367\n",
      "Iteration: 4610 Objective Function: 3.0922285112828227\n",
      "Iteration: 4620 Objective Function: 3.0849177286717717\n",
      "Iteration: 4630 Objective Function: 3.077654999821186\n",
      "Iteration: 4640 Objective Function: 3.0704400088737103\n",
      "Iteration: 4650 Objective Function: 3.063272442048249\n",
      "Iteration: 4660 Objective Function: 3.0561519876261287\n",
      "Iteration: 4670 Objective Function: 3.0490783359376\n",
      "Iteration: 4680 Objective Function: 3.042051179348391\n",
      "Iteration: 4690 Objective Function: 3.035070212246311\n",
      "Iteration: 4700 Objective Function: 3.0281351310279065\n",
      "Iteration: 4710 Objective Function: 3.0212456340854086\n",
      "Iteration: 4720 Objective Function: 3.014401421793396\n",
      "Iteration: 4730 Objective Function: 3.007602196495996\n",
      "Iteration: 4740 Objective Function: 3.0008476624937734\n",
      "Iteration: 4750 Objective Function: 2.994137526030877\n",
      "Iteration: 4760 Objective Function: 2.9874714952824193\n",
      "Iteration: 4770 Objective Function: 2.980849280341598\n",
      "Iteration: 4780 Objective Function: 2.974270593207212\n",
      "Iteration: 4790 Objective Function: 2.967735147771024\n",
      "Iteration: 4800 Objective Function: 2.9612426598054857\n",
      "Iteration: 4810 Objective Function: 2.9547928469511846\n",
      "Iteration: 4820 Objective Function: 2.948385428704723\n",
      "Iteration: 4830 Objective Function: 2.9420201264064114\n",
      "Iteration: 4840 Objective Function: 2.9356966632281876\n",
      "Iteration: 4850 Objective Function: 2.9294147641616224\n",
      "Iteration: 4860 Objective Function: 2.923174156005855\n",
      "Iteration: 4870 Objective Function: 2.9169745673558345\n",
      "Iteration: 4880 Objective Function: 2.9108157285904066\n",
      "Iteration: 4890 Objective Function: 2.9046973718606526\n",
      "Iteration: 4900 Objective Function: 2.8986192310782593\n",
      "Iteration: 4910 Objective Function: 2.892581041903862\n",
      "Iteration: 4920 Objective Function: 2.8865825417356037\n",
      "Iteration: 4930 Objective Function: 2.880623469697726\n",
      "Iteration: 4940 Objective Function: 2.8747035666292033\n",
      "Iteration: 4950 Objective Function: 2.868822575072501\n",
      "Iteration: 4960 Objective Function: 2.862980239262284\n",
      "Iteration: 4970 Objective Function: 2.857176305114412\n",
      "Iteration: 4980 Objective Function: 2.851410520214843\n",
      "Iteration: 4990 Objective Function: 2.8456826338086523\n",
      "Iteration: 5000 Objective Function: 2.8399923967890808\n",
      "Iteration: 5010 Objective Function: 2.8343395616867726\n",
      "Iteration: 5020 Objective Function: 2.828723882659049\n",
      "Iteration: 5030 Objective Function: 2.8231451154790683\n",
      "Iteration: 5040 Objective Function: 2.817603017525299\n",
      "Iteration: 5050 Objective Function: 2.8120973477710316\n",
      "Iteration: 5060 Objective Function: 2.806627866773768\n",
      "Iteration: 5070 Objective Function: 2.801194336664859\n",
      "Iteration: 5080 Objective Function: 2.795796521139186\n",
      "Iteration: 5090 Objective Function: 2.7904341854448824\n",
      "Iteration: 5100 Objective Function: 2.7851070963730686\n",
      "Iteration: 5110 Objective Function: 2.779815022247738\n",
      "Iteration: 5120 Objective Function: 2.774557732915759\n",
      "Iteration: 5130 Objective Function: 2.769334999736703\n",
      "Iteration: 5140 Objective Function: 2.764146595573077\n",
      "Iteration: 5150 Objective Function: 2.7589922947803096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5160 Objective Function: 2.7538718731970118\n",
      "Iteration: 5170 Objective Function: 2.7487851081351926\n",
      "Iteration: 5180 Objective Function: 2.743731778370634\n",
      "Iteration: 5190 Objective Function: 2.738711664133148\n",
      "Iteration: 5200 Objective Function: 2.7337245470971623\n",
      "Iteration: 5210 Objective Function: 2.728770210372116\n",
      "Iteration: 5220 Objective Function: 2.723848438493092\n",
      "Iteration: 5230 Objective Function: 2.718959017411443\n",
      "Iteration: 5240 Objective Function: 2.7141017344853857\n",
      "Iteration: 5250 Objective Function: 2.7092763784709537\n",
      "Iteration: 5260 Objective Function: 2.704482739512555\n",
      "Iteration: 5270 Objective Function: 2.699720609134057\n",
      "Iteration: 5280 Objective Function: 2.6949897802296543\n",
      "Iteration: 5290 Objective Function: 2.690290047054777\n",
      "Iteration: 5300 Objective Function: 2.6856212052172705\n",
      "Iteration: 5310 Objective Function: 2.680983051668438\n",
      "Iteration: 5320 Objective Function: 2.67637538469418\n",
      "Iteration: 5330 Objective Function: 2.6717980039063502\n",
      "Iteration: 5340 Objective Function: 2.667250710233871\n",
      "Iteration: 5350 Objective Function: 2.662733305914177\n",
      "Iteration: 5360 Objective Function: 2.6582455944846526\n",
      "Iteration: 5370 Objective Function: 2.653787380773941\n",
      "Iteration: 5380 Objective Function: 2.649358470893629\n",
      "Iteration: 5390 Objective Function: 2.644958672229646\n",
      "Iteration: 5400 Objective Function: 2.640587793434072\n",
      "Iteration: 5410 Objective Function: 2.6362456444166487\n",
      "Iteration: 5420 Objective Function: 2.631932036336596\n",
      "Iteration: 5430 Objective Function: 2.627646781594361\n",
      "Iteration: 5440 Objective Function: 2.623389693823568\n",
      "Iteration: 5450 Objective Function: 2.6191605878827047\n",
      "Iteration: 5460 Objective Function: 2.614959279847283\n",
      "Iteration: 5470 Objective Function: 2.6107855870017134\n",
      "Iteration: 5480 Objective Function: 2.60663932783141\n",
      "Iteration: 5490 Objective Function: 2.60252032201489\n",
      "Iteration: 5500 Objective Function: 2.5984283904159047\n",
      "Iteration: 5510 Objective Function: 2.594363355075645\n",
      "Iteration: 5520 Objective Function: 2.5903250392050805\n",
      "Iteration: 5530 Objective Function: 2.5863132671771796\n",
      "Iteration: 5540 Objective Function: 2.5823278645193066\n",
      "Iteration: 5550 Objective Function: 2.5783686579056684\n",
      "Iteration: 5560 Objective Function: 2.5744354751496776\n",
      "Iteration: 5570 Objective Function: 2.5705281451966\n",
      "Iteration: 5580 Objective Function: 2.566646498115999\n",
      "Iteration: 5590 Objective Function: 2.562790365094376\n",
      "Iteration: 5600 Objective Function: 2.558959578427915\n",
      "Iteration: 5610 Objective Function: 2.5551539715150215\n",
      "Iteration: 5620 Objective Function: 2.5513733788492665\n",
      "Iteration: 5630 Objective Function: 2.5476176360120144\n",
      "Iteration: 5640 Objective Function: 2.54388657966544\n",
      "Iteration: 5650 Objective Function: 2.540180047545216\n",
      "Iteration: 5660 Objective Function: 2.5364978784536953\n",
      "Iteration: 5670 Objective Function: 2.5328399122527334\n",
      "Iteration: 5680 Objective Function: 2.5292059898567594\n",
      "Iteration: 5690 Objective Function: 2.5255959532259076\n",
      "Iteration: 5700 Objective Function: 2.5220096453590566\n",
      "Iteration: 5710 Objective Function: 2.5184469102871274\n",
      "Iteration: 5720 Objective Function: 2.514907593066139\n",
      "Iteration: 5730 Objective Function: 2.5113915397706394\n",
      "Iteration: 5740 Objective Function: 2.507898597486884\n",
      "Iteration: 5750 Objective Function: 2.504428614306213\n",
      "Iteration: 5760 Objective Function: 2.500981439318505\n",
      "Iteration: 5770 Objective Function: 2.497556922605531\n",
      "Iteration: 5780 Objective Function: 2.4941549152345077\n",
      "Iteration: 5790 Objective Function: 2.4907752692515874\n",
      "Iteration: 5800 Objective Function: 2.4874178376753617\n",
      "Iteration: 5810 Objective Function: 2.484082474490638\n",
      "Iteration: 5820 Objective Function: 2.4807690346418765\n",
      "Iteration: 5830 Objective Function: 2.477477374027045\n",
      "Iteration: 5840 Objective Function: 2.4742073494912655\n",
      "Iteration: 5850 Objective Function: 2.4709588188206753\n",
      "Iteration: 5860 Objective Function: 2.4677316407360546\n",
      "Iteration: 5870 Objective Function: 2.4645256748869913\n",
      "Iteration: 5880 Objective Function: 2.461340781845443\n",
      "Iteration: 5890 Objective Function: 2.4581768230998904\n",
      "Iteration: 5900 Objective Function: 2.455033661049278\n",
      "Iteration: 5910 Objective Function: 2.451911158996928\n",
      "Iteration: 5920 Objective Function: 2.448809181144733\n",
      "Iteration: 5930 Objective Function: 2.445727592587152\n",
      "Iteration: 5940 Objective Function: 2.4426662593053816\n",
      "Iteration: 5950 Objective Function: 2.4396250481615693\n",
      "Iteration: 5960 Objective Function: 2.436603826892911\n",
      "Iteration: 5970 Objective Function: 2.4336024641060052\n",
      "Iteration: 5980 Objective Function: 2.430620829271066\n",
      "Iteration: 5990 Objective Function: 2.4276587927163273\n",
      "Iteration: 6000 Objective Function: 2.42471622562233\n",
      "Iteration: 6010 Objective Function: 2.4217930000163412\n",
      "Iteration: 6020 Objective Function: 2.41888898876677\n",
      "Iteration: 6030 Objective Function: 2.416004065577725\n",
      "Iteration: 6040 Objective Function: 2.413138104983404\n",
      "Iteration: 6050 Objective Function: 2.41029098234272\n",
      "Iteration: 6060 Objective Function: 2.4074625738338136\n",
      "Iteration: 6070 Objective Function: 2.404652756448757\n",
      "Iteration: 6080 Objective Function: 2.401861407988109\n",
      "Iteration: 6090 Objective Function: 2.3990884070556593\n",
      "Iteration: 6100 Objective Function: 2.3963336330531524\n",
      "Iteration: 6110 Objective Function: 2.393596966175033\n",
      "Iteration: 6120 Objective Function: 2.3908782874031678\n",
      "Iteration: 6130 Objective Function: 2.388177478501804\n",
      "Iteration: 6140 Objective Function: 2.3854944220122727\n",
      "Iteration: 6150 Objective Function: 2.382829001248024\n",
      "Iteration: 6160 Objective Function: 2.380181100289509\n",
      "Iteration: 6170 Objective Function: 2.377550603979019\n",
      "Iteration: 6180 Objective Function: 2.374937397915869\n",
      "Iteration: 6190 Objective Function: 2.3723413684512544\n",
      "Iteration: 6200 Objective Function: 2.369762402683479\n",
      "Iteration: 6210 Objective Function: 2.367200388452864\n",
      "Iteration: 6220 Objective Function: 2.3646552143369974\n",
      "Iteration: 6230 Objective Function: 2.3621267696458386\n",
      "Iteration: 6240 Objective Function: 2.3596149444169097\n",
      "Iteration: 6250 Objective Function: 2.3571196294104912\n",
      "Iteration: 6260 Objective Function: 2.354640716104951\n",
      "Iteration: 6270 Objective Function: 2.3521780966919312\n",
      "Iteration: 6280 Objective Function: 2.3497316640717107\n",
      "Iteration: 6290 Objective Function: 2.3473013118485246\n",
      "Iteration: 6300 Objective Function: 2.344886934325955\n",
      "Iteration: 6310 Objective Function: 2.34248842650233\n",
      "Iteration: 6320 Objective Function: 2.3401056840661427\n",
      "Iteration: 6330 Objective Function: 2.3377386033915317\n",
      "Iteration: 6340 Objective Function: 2.3353870815337445\n",
      "Iteration: 6350 Objective Function: 2.3330510162247617\n",
      "Iteration: 6360 Objective Function: 2.3307303058686752\n",
      "Iteration: 6370 Objective Function: 2.3284248495374045\n",
      "Iteration: 6380 Objective Function: 2.3261345469663035\n",
      "Iteration: 6390 Objective Function: 2.3238592985497246\n",
      "Iteration: 6400 Objective Function: 2.321599005336715\n",
      "Iteration: 6410 Objective Function: 2.3193535690267546\n",
      "Iteration: 6420 Objective Function: 2.3171228919654743\n",
      "Iteration: 6430 Objective Function: 2.3149068771403574\n",
      "Iteration: 6440 Objective Function: 2.312705428176532\n",
      "Iteration: 6450 Objective Function: 2.310518449332635\n",
      "Iteration: 6460 Objective Function: 2.3083458454965786\n",
      "Iteration: 6470 Objective Function: 2.3061875221814665\n",
      "Iteration: 6480 Objective Function: 2.3040433855214797\n",
      "Iteration: 6490 Objective Function: 2.3019133422677447\n",
      "Iteration: 6500 Objective Function: 2.2997972997843226\n",
      "Iteration: 6510 Objective Function: 2.297695166044207\n",
      "Iteration: 6520 Objective Function: 2.2956068496252033\n",
      "Iteration: 6530 Objective Function: 2.293532259706139\n",
      "Iteration: 6540 Objective Function: 2.291471306062725\n",
      "Iteration: 6550 Objective Function: 2.2894238990637525\n",
      "Iteration: 6560 Objective Function: 2.28738994966716\n",
      "Iteration: 6570 Objective Function: 2.285369369416131\n",
      "Iteration: 6580 Objective Function: 2.283362070435336\n",
      "Iteration: 6590 Objective Function: 2.2813679654269783\n",
      "Iteration: 6600 Objective Function: 2.279386967667103\n",
      "Iteration: 6610 Objective Function: 2.277418991001808\n",
      "Iteration: 6620 Objective Function: 2.275463949843452\n",
      "Iteration: 6630 Objective Function: 2.2735217591669485\n",
      "Iteration: 6640 Objective Function: 2.2715923345061664\n",
      "Iteration: 6650 Objective Function: 2.269675591950047\n",
      "Iteration: 6660 Objective Function: 2.267771448139182\n",
      "Iteration: 6670 Objective Function: 2.2658798202620165\n",
      "Iteration: 6680 Objective Function: 2.264000626051331\n",
      "Iteration: 6690 Objective Function: 2.2621337837806985\n",
      "Iteration: 6700 Objective Function: 2.2602792122608006\n",
      "Iteration: 6710 Objective Function: 2.2584368308360445\n",
      "Iteration: 6720 Objective Function: 2.256606559380951\n",
      "Iteration: 6730 Objective Function: 2.254788318296708\n",
      "Iteration: 6740 Objective Function: 2.252982028507705\n",
      "Iteration: 6750 Objective Function: 2.251187611458103\n",
      "Iteration: 6760 Objective Function: 2.2494049891084282\n",
      "Iteration: 6770 Objective Function: 2.247634083932103\n",
      "Iteration: 6780 Objective Function: 2.2458748189122093\n",
      "Iteration: 6790 Objective Function: 2.244127117537988\n",
      "Iteration: 6800 Objective Function: 2.242390903801641\n",
      "Iteration: 6810 Objective Function: 2.2406661021949015\n",
      "Iteration: 6820 Objective Function: 2.2389526377059346\n",
      "Iteration: 6830 Objective Function: 2.237250435815834\n",
      "Iteration: 6840 Objective Function: 2.2355594224955766\n",
      "Iteration: 6850 Objective Function: 2.233879524202712\n",
      "Iteration: 6860 Objective Function: 2.232210667878175\n",
      "Iteration: 6870 Objective Function: 2.23055278094316\n",
      "Iteration: 6880 Objective Function: 2.228905791295835\n",
      "Iteration: 6890 Objective Function: 2.2272696273083907\n",
      "Iteration: 6900 Objective Function: 2.2256442178237927\n",
      "Iteration: 6910 Objective Function: 2.2240294921526758\n",
      "Iteration: 6920 Objective Function: 2.222425380070387\n",
      "Iteration: 6930 Objective Function: 2.2208318118138095\n",
      "Iteration: 6940 Objective Function: 2.2192487180784215\n",
      "Iteration: 6950 Objective Function: 2.2176760300151668\n",
      "Iteration: 6960 Objective Function: 2.2161136792276293\n",
      "Iteration: 6970 Objective Function: 2.214561597768879\n",
      "Iteration: 6980 Objective Function: 2.213019718138668\n",
      "Iteration: 6990 Objective Function: 2.211487973280378\n",
      "Iteration: 7000 Objective Function: 2.2099662965781723\n",
      "Iteration: 7010 Objective Function: 2.2084546218540857\n",
      "Iteration: 7020 Objective Function: 2.206952883365129\n",
      "Iteration: 7030 Objective Function: 2.205461015800456\n",
      "Iteration: 7040 Objective Function: 2.2039789542784916\n",
      "Iteration: 7050 Objective Function: 2.2025066343441613\n",
      "Iteration: 7060 Objective Function: 2.201043991965977\n",
      "Iteration: 7070 Objective Function: 2.1995909635334203\n",
      "Iteration: 7080 Objective Function: 2.198147485854034\n",
      "Iteration: 7090 Objective Function: 2.1967134961507115\n",
      "Iteration: 7100 Objective Function: 2.195288932059056\n",
      "Iteration: 7110 Objective Function: 2.193873731624489\n",
      "Iteration: 7120 Objective Function: 2.1924678332997547\n",
      "Iteration: 7130 Objective Function: 2.191071175942065\n",
      "Iteration: 7140 Objective Function: 2.1896836988105597\n",
      "Iteration: 7150 Objective Function: 2.1883053415636686\n",
      "Iteration: 7160 Objective Function: 2.1869360442563734\n",
      "Iteration: 7170 Objective Function: 2.185575747337732\n",
      "Iteration: 7180 Objective Function: 2.1842243916481867\n",
      "Iteration: 7190 Objective Function: 2.1828819184170314\n",
      "Iteration: 7200 Objective Function: 2.1815482692599435\n",
      "Iteration: 7210 Objective Function: 2.180223386176273\n",
      "Iteration: 7220 Objective Function: 2.1789072115466097\n",
      "Iteration: 7230 Objective Function: 2.177599688130343\n",
      "Iteration: 7240 Objective Function: 2.1763007590630385\n",
      "Iteration: 7250 Objective Function: 2.1750103678540604\n",
      "Iteration: 7260 Objective Function: 2.173728458384101\n",
      "Iteration: 7270 Objective Function: 2.1724549749026805\n",
      "Iteration: 7280 Objective Function: 2.171189862025789\n",
      "Iteration: 7290 Objective Function: 2.169933064733495\n",
      "Iteration: 7300 Objective Function: 2.1686845283674425\n",
      "Iteration: 7310 Objective Function: 2.1674441986285746\n",
      "Iteration: 7320 Objective Function: 2.166212021574783\n",
      "Iteration: 7330 Objective Function: 2.1649879436184367\n",
      "Iteration: 7340 Objective Function: 2.163771911524239\n",
      "Iteration: 7350 Objective Function: 2.162563872406702\n",
      "Iteration: 7360 Objective Function: 2.161363773728012\n",
      "Iteration: 7370 Objective Function: 2.1601715632957084\n",
      "Iteration: 7380 Objective Function: 2.1589871892603534\n",
      "Iteration: 7390 Objective Function: 2.157810600113299\n",
      "Iteration: 7400 Objective Function: 2.156641744684527\n",
      "Iteration: 7410 Objective Function: 2.1554805721402865\n",
      "Iteration: 7420 Objective Function: 2.1543270319810146\n",
      "Iteration: 7430 Objective Function: 2.153181074039053\n",
      "Iteration: 7440 Objective Function: 2.1520426484764967\n",
      "Iteration: 7450 Objective Function: 2.1509117057830385\n",
      "Iteration: 7460 Objective Function: 2.1497881967737786\n",
      "Iteration: 7470 Objective Function: 2.1486720725871336\n",
      "Iteration: 7480 Objective Function: 2.1475632846827017\n",
      "Iteration: 7490 Objective Function: 2.146461784839075\n",
      "Iteration: 7500 Objective Function: 2.145367525151852\n",
      "Iteration: 7510 Objective Function: 2.1442804580315262\n",
      "Iteration: 7520 Objective Function: 2.1432005362013404\n",
      "Iteration: 7530 Objective Function: 2.142127712695325\n",
      "Iteration: 7540 Objective Function: 2.1410619408562024\n",
      "Iteration: 7550 Objective Function: 2.140003174333392\n",
      "Iteration: 7560 Objective Function: 2.138951367080957\n",
      "Iteration: 7570 Objective Function: 2.1379064733556135\n",
      "Iteration: 7580 Objective Function: 2.1368684477147846\n",
      "Iteration: 7590 Objective Function: 2.1358372450145446\n",
      "Iteration: 7600 Objective Function: 2.1348128204077215\n",
      "Iteration: 7610 Objective Function: 2.1337951293419213\n",
      "Iteration: 7620 Objective Function: 2.1327841275575983\n",
      "Iteration: 7630 Objective Function: 2.131779771086113\n",
      "Iteration: 7640 Objective Function: 2.1307820162478333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7650 Objective Function: 2.1297908196502537\n",
      "Iteration: 7660 Objective Function: 2.128806138186049\n",
      "Iteration: 7670 Objective Function: 2.1278279290312634\n",
      "Iteration: 7680 Objective Function: 2.1268561496434035\n",
      "Iteration: 7690 Objective Function: 2.125890757759668\n",
      "Iteration: 7700 Objective Function: 2.1249317113949666\n",
      "Iteration: 7710 Objective Function: 2.1239789688402326\n",
      "Iteration: 7720 Objective Function: 2.1230324886605225\n",
      "Iteration: 7730 Objective Function: 2.1220922296932776\n",
      "Iteration: 7740 Objective Function: 2.1211581510464534\n",
      "Iteration: 7750 Objective Function: 2.120230212096827\n",
      "Iteration: 7760 Objective Function: 2.1193083724881756\n",
      "Iteration: 7770 Objective Function: 2.1183925921295566\n",
      "Iteration: 7780 Objective Function: 2.1174828311935268\n",
      "Iteration: 7790 Objective Function: 2.1165790501143977\n",
      "Iteration: 7800 Objective Function: 2.1156812095866484\n",
      "Iteration: 7810 Objective Function: 2.1147892705629925\n",
      "Iteration: 7820 Objective Function: 2.113903194252865\n",
      "Iteration: 7830 Objective Function: 2.1130229421206868\n",
      "Iteration: 7840 Objective Function: 2.1121484758841067\n",
      "Iteration: 7850 Objective Function: 2.1112797575124773\n",
      "Iteration: 7860 Objective Function: 2.110416749225057\n",
      "Iteration: 7870 Objective Function: 2.109559413489525\n",
      "Iteration: 7880 Objective Function: 2.1087077130201552\n",
      "Iteration: 7890 Objective Function: 2.1078616107763906\n",
      "Iteration: 7900 Objective Function: 2.107021069961097\n",
      "Iteration: 7910 Objective Function: 2.1061860540190063\n",
      "Iteration: 7920 Objective Function: 2.1053565266351466\n",
      "Iteration: 7930 Objective Function: 2.1045324517332014\n",
      "Iteration: 7940 Objective Function: 2.1037137934740793\n",
      "Iteration: 7950 Objective Function: 2.1029005162541408\n",
      "Iteration: 7960 Objective Function: 2.1020925847038505\n",
      "Iteration: 7970 Objective Function: 2.1012899636861273\n",
      "Iteration: 7980 Objective Function: 2.100492618294878\n",
      "Iteration: 7990 Objective Function: 2.099700513853362\n",
      "Iteration: 8000 Objective Function: 2.0989136159128767\n",
      "Iteration: 8010 Objective Function: 2.0981318902510653\n",
      "Iteration: 8020 Objective Function: 2.0973553028705685\n",
      "Iteration: 8030 Objective Function: 2.0965838199974898\n",
      "Iteration: 8040 Objective Function: 2.09581740807988\n",
      "Iteration: 8050 Objective Function: 2.0950560337863755\n",
      "Iteration: 8060 Objective Function: 2.094299664004672\n",
      "Iteration: 8070 Objective Function: 2.0935482658401363\n",
      "Iteration: 8080 Objective Function: 2.0928018066143386\n",
      "Iteration: 8090 Objective Function: 2.09206025386362\n",
      "Iteration: 8100 Objective Function: 2.0913235753377517\n",
      "Iteration: 8110 Objective Function: 2.09059173899844\n",
      "Iteration: 8120 Objective Function: 2.0898647130180388\n",
      "Iteration: 8130 Objective Function: 2.089142465778037\n",
      "Iteration: 8140 Objective Function: 2.0884249658677847\n",
      "Iteration: 8150 Objective Function: 2.087712182083116\n",
      "Iteration: 8160 Objective Function: 2.087004083424937\n",
      "Iteration: 8170 Objective Function: 2.0863006390978933\n",
      "Iteration: 8180 Objective Function: 2.0856018185090988\n",
      "Iteration: 8190 Objective Function: 2.0849075912667363\n",
      "Iteration: 8200 Objective Function: 2.0842179271787282\n",
      "Iteration: 8210 Objective Function: 2.0835327962514936\n",
      "Iteration: 8220 Objective Function: 2.082852168688569\n",
      "Iteration: 8230 Objective Function: 2.082176014889319\n",
      "Iteration: 8240 Objective Function: 2.0815043054477327\n",
      "Iteration: 8250 Objective Function: 2.0808370111510475\n",
      "Iteration: 8260 Objective Function: 2.0801741029785537\n",
      "Iteration: 8270 Objective Function: 2.07951555210021\n",
      "Iteration: 8280 Objective Function: 2.0788613298755707\n",
      "Iteration: 8290 Objective Function: 2.0782114078523684\n",
      "Iteration: 8300 Objective Function: 2.077565757765427\n",
      "Iteration: 8310 Objective Function: 2.0769243515353017\n",
      "Iteration: 8320 Objective Function: 2.0762871612671203\n",
      "Iteration: 8330 Objective Function: 2.0756541592493876\n",
      "Iteration: 8340 Objective Function: 2.075025317952725\n",
      "Iteration: 8350 Objective Function: 2.0744006100287287\n",
      "Iteration: 8360 Objective Function: 2.073780008308767\n",
      "Iteration: 8370 Objective Function: 2.073163485802729\n",
      "Iteration: 8380 Objective Function: 2.0725510156979716\n",
      "Iteration: 8390 Objective Function: 2.0719425713580746\n",
      "Iteration: 8400 Objective Function: 2.071338126321674\n",
      "Iteration: 8410 Objective Function: 2.0707376543013853\n",
      "Iteration: 8420 Objective Function: 2.07014112918255\n",
      "Iteration: 8430 Objective Function: 2.069548525022201\n",
      "Iteration: 8440 Objective Function: 2.0689598160478986\n",
      "Iteration: 8450 Objective Function: 2.0683749766565818\n",
      "Iteration: 8460 Objective Function: 2.067793981413488\n",
      "Iteration: 8470 Objective Function: 2.06721680505104\n",
      "Iteration: 8480 Objective Function: 2.066643422467734\n",
      "Iteration: 8490 Objective Function: 2.0660738087270984\n",
      "Iteration: 8500 Objective Function: 2.065507939056496\n",
      "Iteration: 8510 Objective Function: 2.0649457888461837\n",
      "Iteration: 8520 Objective Function: 2.064387333648156\n",
      "Iteration: 8530 Objective Function: 2.0638325491751006\n",
      "Iteration: 8540 Objective Function: 2.0632814112993407\n",
      "Iteration: 8550 Objective Function: 2.0627338960518222\n",
      "Iteration: 8560 Objective Function: 2.0621899796209853\n",
      "Iteration: 8570 Objective Function: 2.0616496383518403\n",
      "Iteration: 8580 Objective Function: 2.0611128487448496\n",
      "Iteration: 8590 Objective Function: 2.06057958745494\n",
      "Iteration: 8600 Objective Function: 2.0600498312904763\n",
      "Iteration: 8610 Objective Function: 2.0595235572123083\n",
      "Iteration: 8620 Objective Function: 2.059000742332663\n",
      "Iteration: 8630 Objective Function: 2.058481363914248\n",
      "Iteration: 8640 Objective Function: 2.0579653993692117\n",
      "Iteration: 8650 Objective Function: 2.057452826258162\n",
      "Iteration: 8660 Objective Function: 2.056943622289182\n",
      "Iteration: 8670 Objective Function: 2.0564377653169696\n",
      "Iteration: 8680 Objective Function: 2.0559352333416956\n",
      "Iteration: 8690 Objective Function: 2.0554360045081443\n",
      "Iteration: 8700 Objective Function: 2.054940057104767\n",
      "Iteration: 8710 Objective Function: 2.054447369562757\n",
      "Iteration: 8720 Objective Function: 2.053957920455035\n",
      "Iteration: 8730 Objective Function: 2.053471688495393\n",
      "Iteration: 8740 Objective Function: 2.0529886525375036\n",
      "Iteration: 8750 Objective Function: 2.05250879157407\n",
      "Iteration: 8760 Objective Function: 2.052032084735856\n",
      "Iteration: 8770 Objective Function: 2.051558511290781\n",
      "Iteration: 8780 Objective Function: 2.0510880506430733\n",
      "Iteration: 8790 Objective Function: 2.050620682332325\n",
      "Iteration: 8800 Objective Function: 2.050156386032625\n",
      "Iteration: 8810 Objective Function: 2.0496951415516387\n",
      "Iteration: 8820 Objective Function: 2.0492369288297496\n",
      "Iteration: 8830 Objective Function: 2.0487817279392178\n",
      "Iteration: 8840 Objective Function: 2.048329519083293\n",
      "Iteration: 8850 Objective Function: 2.0478802825953197\n",
      "Iteration: 8860 Objective Function: 2.0474339989379757\n",
      "Iteration: 8870 Objective Function: 2.046990648702257\n",
      "Iteration: 8880 Objective Function: 2.0465502126067974\n",
      "Iteration: 8890 Objective Function: 2.0461126714969837\n",
      "Iteration: 8900 Objective Function: 2.0456780063440565\n",
      "Iteration: 8910 Objective Function: 2.0452461982443713\n",
      "Iteration: 8920 Objective Function: 2.0448172284185255\n",
      "Iteration: 8930 Objective Function: 2.0443910782105323\n",
      "Iteration: 8940 Objective Function: 2.0439677290870617\n",
      "Iteration: 8950 Objective Function: 2.0435471626365906\n",
      "Iteration: 8960 Objective Function: 2.043129360568624\n",
      "Iteration: 8970 Objective Function: 2.0427143047128338\n",
      "Iteration: 8980 Objective Function: 2.0423019770184365\n",
      "Iteration: 8990 Objective Function: 2.0418923595531786\n",
      "Iteration: 9000 Objective Function: 2.041485434502788\n",
      "Iteration: 9010 Objective Function: 2.0410811841699807\n",
      "Iteration: 9020 Objective Function: 2.0406795909738253\n",
      "Iteration: 9030 Objective Function: 2.040280637449032\n",
      "Iteration: 9040 Objective Function: 2.0398843062449976\n",
      "Iteration: 9050 Objective Function: 2.0394905801252365\n",
      "Iteration: 9060 Objective Function: 2.0390994419665063\n",
      "Iteration: 9070 Objective Function: 2.0387108747581792\n",
      "Iteration: 9080 Objective Function: 2.03832486160136\n",
      "Iteration: 9090 Objective Function: 2.037941385708316\n",
      "Iteration: 9100 Objective Function: 2.0375604304016197\n",
      "Iteration: 9110 Objective Function: 2.037181979113409\n",
      "Iteration: 9120 Objective Function: 2.03680601538482\n",
      "Iteration: 9130 Objective Function: 2.036432522865113\n",
      "Iteration: 9140 Objective Function: 2.0360614853110497\n",
      "Iteration: 9150 Objective Function: 2.0356928865861192\n",
      "Iteration: 9160 Objective Function: 2.035326710659924\n",
      "Iteration: 9170 Objective Function: 2.034962941607417\n",
      "Iteration: 9180 Objective Function: 2.0346015636081978\n",
      "Iteration: 9190 Objective Function: 2.0342425609458967\n",
      "Iteration: 9200 Objective Function: 2.0338859180074365\n",
      "Iteration: 9210 Objective Function: 2.0335316192823143\n",
      "Iteration: 9220 Objective Function: 2.0331796493620833\n",
      "Iteration: 9230 Objective Function: 2.032829992939459\n",
      "Iteration: 9240 Objective Function: 2.0324826348078524\n",
      "Iteration: 9250 Objective Function: 2.032137559860587\n",
      "Iteration: 9260 Objective Function: 2.0317947530903093\n",
      "Iteration: 9270 Objective Function: 2.031454199588299\n",
      "Iteration: 9280 Objective Function: 2.0311158845438158\n",
      "Iteration: 9290 Objective Function: 2.030779793243482\n",
      "Iteration: 9300 Objective Function: 2.030445911070638\n",
      "Iteration: 9310 Objective Function: 2.0301142235046985\n",
      "Iteration: 9320 Objective Function: 2.029784716120503\n",
      "Iteration: 9330 Objective Function: 2.0294573745877336\n",
      "Iteration: 9340 Objective Function: 2.0291321846702353\n",
      "Iteration: 9350 Objective Function: 2.028809132225466\n",
      "Iteration: 9360 Objective Function: 2.0284882032038203\n",
      "Iteration: 9370 Objective Function: 2.028169383648004\n",
      "Iteration: 9380 Objective Function: 2.027852659692561\n",
      "Iteration: 9390 Objective Function: 2.027538017563072\n",
      "Iteration: 9400 Objective Function: 2.027225443575716\n",
      "Iteration: 9410 Objective Function: 2.026914924136596\n",
      "Iteration: 9420 Objective Function: 2.026606445741157\n",
      "Iteration: 9430 Objective Function: 2.026299994973647\n",
      "Iteration: 9440 Objective Function: 2.0259955585064517\n",
      "Iteration: 9450 Objective Function: 2.0256931230995767\n",
      "Iteration: 9460 Objective Function: 2.0253926756000786\n",
      "Iteration: 9470 Objective Function: 2.0250942029414403\n",
      "Iteration: 9480 Objective Function: 2.0247976921430224\n",
      "Iteration: 9490 Objective Function: 2.0245031303095127\n",
      "Iteration: 9500 Objective Function: 2.0242105046303953\n",
      "Iteration: 9510 Objective Function: 2.023919802379318\n",
      "Iteration: 9520 Objective Function: 2.0236310109136006\n",
      "Iteration: 9530 Objective Function: 2.0233441176736386\n",
      "Iteration: 9540 Objective Function: 2.023059110182402\n",
      "Iteration: 9550 Objective Function: 2.0227759760448945\n",
      "Iteration: 9560 Objective Function: 2.022494702947521\n",
      "Iteration: 9570 Objective Function: 2.0222152786577023\n",
      "Iteration: 9580 Objective Function: 2.0219376910232025\n",
      "Iteration: 9590 Objective Function: 2.021661927971717\n",
      "Iteration: 9600 Objective Function: 2.0213879775102424\n",
      "Iteration: 9610 Objective Function: 2.021115827724666\n",
      "Iteration: 9620 Objective Function: 2.0208454667791025\n",
      "Iteration: 9630 Objective Function: 2.020576882915524\n",
      "Iteration: 9640 Objective Function: 2.020310064453181\n",
      "Iteration: 9650 Objective Function: 2.020044999788089\n",
      "Iteration: 9660 Objective Function: 2.0197816773925528\n",
      "Iteration: 9670 Objective Function: 2.0195200858146234\n",
      "Iteration: 9680 Objective Function: 2.019260213677657\n",
      "Iteration: 9690 Objective Function: 2.0190020496797487\n",
      "Iteration: 9700 Objective Function: 2.0187455825933225\n",
      "Iteration: 9710 Objective Function: 2.0184908012645737\n",
      "Iteration: 9720 Objective Function: 2.01823769461302\n",
      "Iteration: 9730 Objective Function: 2.017986251631011\n",
      "Iteration: 9740 Objective Function: 2.0177364613832607\n",
      "Iteration: 9750 Objective Function: 2.0174883130063392\n",
      "Iteration: 9760 Objective Function: 2.017241795708235\n",
      "Iteration: 9770 Objective Function: 2.016996898767872\n",
      "Iteration: 9780 Objective Function: 2.016753611534638\n",
      "Iteration: 9790 Objective Function: 2.016511923427932\n",
      "Iteration: 9800 Objective Function: 2.016271823936692\n",
      "Iteration: 9810 Objective Function: 2.0160333026189643\n",
      "Iteration: 9820 Objective Function: 2.0157963491014192\n",
      "Iteration: 9830 Objective Function: 2.015560953078902\n",
      "Iteration: 9840 Objective Function: 2.015327104313993\n",
      "Iteration: 9850 Objective Function: 2.0150947926365763\n",
      "Iteration: 9860 Objective Function: 2.0148640079433875\n",
      "Iteration: 9870 Objective Function: 2.014634740197544\n",
      "Iteration: 9880 Objective Function: 2.0144069794281703\n",
      "Iteration: 9890 Objective Function: 2.0141807157299123\n",
      "Iteration: 9900 Objective Function: 2.013955939262524\n",
      "Iteration: 9910 Objective Function: 2.0137326402504203\n",
      "Iteration: 9920 Objective Function: 2.0135108089823195\n",
      "Iteration: 9930 Objective Function: 2.0132904358107226\n",
      "Iteration: 9940 Objective Function: 2.013071511151574\n",
      "Iteration: 9950 Objective Function: 2.0128540254837963\n",
      "Iteration: 9960 Objective Function: 2.0126379693489103\n",
      "Iteration: 9970 Objective Function: 2.0124233333505996\n",
      "Iteration: 9980 Objective Function: 2.0122101081542962\n",
      "Iteration: 9990 Objective Function: 2.011998284486808\n",
      "Iteration: 10000 Objective Function: 2.0117878531358886\n",
      "Iteration: 10010 Objective Function: 2.011578804949855\n",
      "Iteration: 10020 Objective Function: 2.011371130837146\n",
      "Iteration: 10030 Objective Function: 2.011164821765999\n",
      "Iteration: 10040 Objective Function: 2.010959868763988\n",
      "Iteration: 10050 Objective Function: 2.0107562629176767\n",
      "Iteration: 10060 Objective Function: 2.010553995372216\n",
      "Iteration: 10070 Objective Function: 2.010353057330945\n",
      "Iteration: 10080 Objective Function: 2.0101534400550505\n",
      "Iteration: 10090 Objective Function: 2.009955134863127\n",
      "Iteration: 10100 Objective Function: 2.0097581331308683\n",
      "Iteration: 10110 Objective Function: 2.009562426290622\n",
      "Iteration: 10120 Objective Function: 2.009368005831076\n",
      "Iteration: 10130 Objective Function: 2.009174863296855\n",
      "Iteration: 10140 Objective Function: 2.008982990288133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10150 Objective Function: 2.0087923784603485\n",
      "Iteration: 10160 Objective Function: 2.0086030195237483\n",
      "Iteration: 10170 Objective Function: 2.0084149052430798\n",
      "Iteration: 10180 Objective Function: 2.008228027437232\n",
      "Iteration: 10190 Objective Function: 2.0080423779788448\n",
      "Iteration: 10200 Objective Function: 2.007857948794016\n",
      "Iteration: 10210 Objective Function: 2.0076747318618553\n",
      "Iteration: 10220 Objective Function: 2.007492719214256\n",
      "Iteration: 10230 Objective Function: 2.0073119029354567\n",
      "Iteration: 10240 Objective Function: 2.007132275161705\n",
      "Iteration: 10250 Objective Function: 2.006953828080983\n",
      "Iteration: 10260 Objective Function: 2.00677655393258\n",
      "Iteration: 10270 Objective Function: 2.006600445006838\n",
      "Iteration: 10280 Objective Function: 2.006425493644728\n",
      "Iteration: 10290 Objective Function: 2.0062516922375964\n",
      "Iteration: 10300 Objective Function: 2.0060790332267797\n",
      "Iteration: 10310 Objective Function: 2.0059075091033245\n",
      "Iteration: 10320 Objective Function: 2.0057371124076124\n",
      "Iteration: 10330 Objective Function: 2.0055678357290656\n",
      "Iteration: 10340 Objective Function: 2.0053996717058067\n",
      "Iteration: 10350 Objective Function: 2.0052326130243556\n",
      "Iteration: 10360 Objective Function: 2.0050666524193135\n",
      "Iteration: 10370 Objective Function: 2.0049017826730013\n",
      "Iteration: 10380 Objective Function: 2.0047379966152348\n",
      "Iteration: 10390 Objective Function: 2.0045752871229165\n",
      "Iteration: 10400 Objective Function: 2.0044136471197915\n",
      "Iteration: 10410 Objective Function: 2.0042530695761083\n",
      "Iteration: 10420 Objective Function: 2.0040935475083077\n",
      "Iteration: 10430 Objective Function: 2.003935073978762\n",
      "Iteration: 10440 Objective Function: 2.003777642095442\n",
      "Iteration: 10450 Objective Function: 2.0036212450115864\n",
      "Iteration: 10460 Objective Function: 2.0034658759254658\n",
      "Iteration: 10470 Objective Function: 2.0033115280800677\n",
      "Iteration: 10480 Objective Function: 2.0031581947627606\n",
      "Iteration: 10490 Objective Function: 2.0030058693050625\n",
      "Iteration: 10500 Objective Function: 2.0028545450823207\n",
      "Iteration: 10510 Objective Function: 2.0027042155134085\n",
      "Iteration: 10520 Objective Function: 2.002554874060467\n",
      "Iteration: 10530 Objective Function: 2.002406514228621\n",
      "Iteration: 10540 Objective Function: 2.0022591295656733\n",
      "Iteration: 10550 Objective Function: 2.002112713661842\n",
      "Iteration: 10560 Objective Function: 2.001967260149462\n",
      "Iteration: 10570 Objective Function: 2.001822762702749\n",
      "Iteration: 10580 Objective Function: 2.001679215037482\n",
      "Iteration: 10590 Objective Function: 2.0015366109107626\n",
      "Iteration: 10600 Objective Function: 2.001394944120696\n",
      "Iteration: 10610 Objective Function: 2.0012542085061735\n",
      "Iteration: 10620 Objective Function: 2.001114397946573\n",
      "Iteration: 10630 Objective Function: 2.000975506361537\n",
      "Iteration: 10640 Objective Function: 2.0008375277106136\n",
      "Iteration: 10650 Objective Function: 2.0007004559931163\n",
      "Iteration: 10660 Objective Function: 2.0005642852477545\n",
      "Iteration: 10670 Objective Function: 2.0004290095524455\n",
      "Iteration: 10680 Objective Function: 2.000294623024038\n",
      "Iteration: 10690 Objective Function: 2.0001611198180242\n",
      "Iteration: 10700 Objective Function: 2.0000284941283395\n",
      "Iteration: 10710 Objective Function: 1.9998967401870478\n",
      "Iteration: 10720 Objective Function: 1.9997658522641846\n",
      "Iteration: 10730 Objective Function: 1.9996358246673915\n",
      "Iteration: 10740 Objective Function: 1.9995066517417415\n",
      "Iteration: 10750 Objective Function: 1.9993783278694963\n",
      "Iteration: 10760 Objective Function: 1.9992508474698225\n",
      "Iteration: 10770 Objective Function: 1.9991242049985738\n",
      "Iteration: 10780 Objective Function: 1.9989983949480523\n",
      "Iteration: 10790 Objective Function: 1.9988734118467477\n",
      "Iteration: 10800 Objective Function: 1.9987492502591522\n",
      "Iteration: 10810 Objective Function: 1.9986259047854327\n",
      "Iteration: 10820 Objective Function: 1.9985033700612849\n",
      "Iteration: 10830 Objective Function: 1.9983816407576458\n",
      "Iteration: 10840 Objective Function: 1.9982607115804847\n",
      "Iteration: 10850 Objective Function: 1.998140577270588\n",
      "Iteration: 10860 Objective Function: 1.9980212326032842\n",
      "Iteration: 10870 Objective Function: 1.9979026723882505\n",
      "Iteration: 10880 Objective Function: 1.997784891469297\n",
      "Iteration: 10890 Objective Function: 1.9976678847240914\n",
      "Iteration: 10900 Objective Function: 1.997551647064013\n",
      "Iteration: 10910 Objective Function: 1.9974361734338575\n",
      "Iteration: 10920 Objective Function: 1.9973214588116541\n",
      "Iteration: 10930 Objective Function: 1.9972074982084473\n",
      "Iteration: 10940 Objective Function: 1.997094286668073\n",
      "Iteration: 10950 Objective Function: 1.9969818192669468\n",
      "Iteration: 10960 Objective Function: 1.9968700911138242\n",
      "Iteration: 10970 Objective Function: 1.9967590973496594\n",
      "Iteration: 10980 Objective Function: 1.9966488331472851\n",
      "Iteration: 10990 Objective Function: 1.996539293711318\n",
      "Iteration: 11000 Objective Function: 1.9964304742778456\n",
      "Iteration: 11010 Objective Function: 1.996322370114311\n",
      "Iteration: 11020 Objective Function: 1.9962149765192472\n",
      "Iteration: 11030 Objective Function: 1.9961082888220778\n",
      "Iteration: 11040 Objective Function: 1.9960023023829452\n",
      "Iteration: 11050 Objective Function: 1.99589701259248\n",
      "Iteration: 11060 Objective Function: 1.9957924148716046\n",
      "Iteration: 11070 Objective Function: 1.995688504671353\n",
      "Iteration: 11080 Objective Function: 1.9955852774726603\n",
      "Iteration: 11090 Objective Function: 1.9954827287861479\n",
      "Iteration: 11100 Objective Function: 1.9953808541519613\n",
      "Iteration: 11110 Objective Function: 1.9952796491395532\n",
      "Iteration: 11120 Objective Function: 1.9951791093475\n",
      "Iteration: 11130 Objective Function: 1.9950792304033187\n"
     ]
    }
   ],
   "source": [
    "# Question 3 Answer Code\n",
    "# Write code for you answer to this question in this box\n",
    "# Do not delete these comments, otherwise you will get zero for this answer.\n",
    "# Make sure your code has run and the answer is correct *before* submitting your notebook for marking.\n",
    "\n",
    "m = -0.4\n",
    "c = 80         \n",
    "x_test = np.linspace(1890, 2020, 130)[:, None]\n",
    "\n",
    "error = ((y - m*x - c)**2).sum()\n",
    "change = error\n",
    "i = 0\n",
    "while change > 0.0001:\n",
    "    m = ((y - c)*x).sum()/(x**2).sum()   \n",
    "    c = (y - m*x).mean()\n",
    "\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        nerror = ((y - m*x - c)**2).sum()\n",
    "        print('Iteration:',i,'Objective Function:',nerror)\n",
    "        change = abs(nerror - error)\n",
    "        error = nerror\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.015963380659913314\n",
      "34.73035508819704\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_test = m*x_test + c\n",
    "plt.plot(x_test, f_test, 'b-')\n",
    "plt.plot(x, y, 'rx')\n",
    "print(m)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 Answer Here\n",
    "\n",
    "We need more than 10000 iterations to get to the solution, and we notice that if we update the parameter c first and then m, we need even more iterations. This is happening because the parameters are correlated. If the optimization surface was uncorrelated (i.e. independent in both directions) we could optimize in two steps. However, in our case, the parameters are not independent, since they appear in the error function together, and this leaves a strong correlation between m and c, so we have to do a lot of 'zig-zags' to reach the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Input Solution with Linear Algebra\n",
    "\n",
    "You've now seen how slow it can be to perform a coordinate ascent on a system. Another approach to solving the system (which is not always possible, particularly in *non-linear* systems) is to go direct to the minimum. To do this we need to introduce *linear algebra*. We will represent all our errors and functions in the form of linear algebra. \n",
    "\n",
    "As we mentioned above, linear algebra is just a shorthand for performing lots of multiplications and additions simultaneously. What does it have to do with our system then? Well the first thing to note is that the linear function we were trying to fit has the following form:\n",
    "$$\n",
    "f(x) = mx + c\n",
    "$$\n",
    "the classical form for a straight line. From a linear algebraic perspective we are looking for multiplications and additions. We are also looking to separate our parameters from our data. The data is the *givens* remember, in French the word is donnes literally translated means *givens* that's great, because we don't need to change the data, what we need to change are the parameters (or variables) of the model. In this function the data comes in through $x$, and the parameters are $m$ and $c$. \n",
    "\n",
    "What we'd like to create is a vector of parameters and a vector of data. Then we could represent the system with vectors that represent the data, and vectors that represent the parameters. \n",
    "\n",
    "We look to turn the multiplications and additions into a linear algebraic form, we have one multiplication ($m\\times c$) and one addition ($mx + c$). But we can turn this into a inner product by writing it in the following way,\n",
    "$$\n",
    "f(x) = m \\times x + c \\times 1,\n",
    "$$\n",
    "in other words we've extracted the unit value, from the offset, $c$. We can think of this unit value like an extra item of data, because it is always given to us, and it is always set to 1 (unlike regular data, which is likely to vary!). We can therefore write each input data location, $\\mathbf{x}$, as a vector\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} 1\\\\ x\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Now we choose to also turn our parameters into a vector. The parameter vector will be defined to contain \n",
    "$$\n",
    "\\mathbf{w} = \\begin{bmatrix} c \\\\ m\\end{bmatrix}\n",
    "$$\n",
    "because if we now take the inner product between these to vectors we recover\n",
    "$$\n",
    "\\mathbf{x}\\cdot\\mathbf{w} = 1 \\times c + x \\times m = mx + c\n",
    "$$\n",
    "In `numpy` we can define this vector as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the vector w\n",
    "w = np.zeros(shape=(2, 1))\n",
    "w[0] = m\n",
    "w[1] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the equivalence between original operation and an operation in vector space. Whilst the notation here isn't a lot shorter, the beauty is that we will be able to add as many features as we like and still keep the same representation. In general, we are now moving to a system where each of our predictions is given by an inner product. When we want to represent a linear product in linear algebra, we tend to do it with the transpose operation, so since we have $\\mathbf{a}\\cdot\\mathbf{b} = \\mathbf{a}^\\top\\mathbf{b}$ we can write\n",
    "$$\n",
    "f(\\mathbf{x}_i) = \\mathbf{x}_i^\\top\\mathbf{w}.\n",
    "$$\n",
    "Where we've assumed that each data point, $\\mathbf{x}_i$, is now written by appending a 1 onto the original vector\n",
    "$$\n",
    "\\mathbf{x}_i = \n",
    "\\begin{bmatrix} \n",
    "1 \\\\\n",
    "x_i\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## Design Matrix\n",
    "\n",
    "We can do this for the entire data set to form a [*design matrix*](http://en.wikipedia.org/wiki/Design_matrix) $\\mathbf{X}$,\n",
    "\n",
    "$$\\mathbf{X} = \\begin{bmatrix} \n",
    "\\mathbf{x}_1^\\top \\\\\\ \n",
    "\\mathbf{x}_2^\\top \\\\\\ \n",
    "\\vdots \\\\\\\n",
    "\\mathbf{x}_n^\\top\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & x_1 \\\\\\\n",
    "1 & x_2 \\\\\\\n",
    "\\vdots & \\vdots \\\\\\\n",
    "1 & x_n \n",
    "\\end{bmatrix},$$\n",
    "\n",
    "which in `numpy` can be done with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 1.896e+03]\n",
      " [1.000e+00 1.900e+03]\n",
      " [1.000e+00 1.904e+03]\n",
      " [1.000e+00 1.908e+03]\n",
      " [1.000e+00 1.912e+03]\n",
      " [1.000e+00 1.920e+03]\n",
      " [1.000e+00 1.924e+03]\n",
      " [1.000e+00 1.928e+03]\n",
      " [1.000e+00 1.932e+03]\n",
      " [1.000e+00 1.936e+03]\n",
      " [1.000e+00 1.948e+03]\n",
      " [1.000e+00 1.952e+03]\n",
      " [1.000e+00 1.956e+03]\n",
      " [1.000e+00 1.960e+03]\n",
      " [1.000e+00 1.964e+03]\n",
      " [1.000e+00 1.968e+03]\n",
      " [1.000e+00 1.972e+03]\n",
      " [1.000e+00 1.976e+03]\n",
      " [1.000e+00 1.980e+03]\n",
      " [1.000e+00 1.984e+03]\n",
      " [1.000e+00 1.988e+03]\n",
      " [1.000e+00 1.992e+03]\n",
      " [1.000e+00 1.996e+03]\n",
      " [1.000e+00 2.000e+03]\n",
      " [1.000e+00 2.004e+03]\n",
      " [1.000e+00 2.008e+03]\n",
      " [1.000e+00 2.012e+03]]\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack((np.ones_like(x), x))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the Objective with Linear Algebra\n",
    "\n",
    "When we think of the objective function, we can think of it as the errors where the error is defined in a similar way to what it was in Legendre's day $y_i - f(\\mathbf{x}_i)$, in statistics these errors are also sometimes called [*residuals*](http://en.wikipedia.org/wiki/Errors_and_residuals_in_statistics). So we can think as the objective and the prediction function as two separate parts, first we have,\n",
    "$$\n",
    "E(\\mathbf{w}) = \\sum_{i=1}^n (y_i - f(\\mathbf{x}_i; \\mathbf{w}))^2,\n",
    "$$\n",
    "where we've made the function $f(\\cdot)$'s dependence on the parameters $\\mathbf{w}$ explicit in this equation. Then we have the definition of the function itself,\n",
    "$$\n",
    "f(\\mathbf{x}_i; \\mathbf{w}) = \\mathbf{x}_i^\\top \\mathbf{w}.\n",
    "$$\n",
    "Let's look again at these two equations and see if we can identify any inner products. The first equation is a sum of squares, which is promising. Any sum of squares can be represented by an inner product,\n",
    "$$\n",
    "a = \\sum_{i=1}^{k} b^2_i = \\mathbf{b}^\\top\\mathbf{b},\n",
    "$$\n",
    "so if we wish to represent $E(\\mathbf{w})$ in this way, all we need to do is convert the sum operator to an inner product. We can get a vector from that sum operator by placing both $y_i$ and $f(\\mathbf{x}_i; \\mathbf{w})$ into vectors, which we do by defining \n",
    "$$\n",
    "\\mathbf{y} = \\begin{bmatrix}y_1\\\\y_2\\\\ \\vdots \\\\ y_n\\end{bmatrix}\n",
    "$$\n",
    "and defining\n",
    "$$\n",
    "\\mathbf{f}(\\mathbf{X}; \\mathbf{w}) = \\begin{bmatrix}f(\\mathbf{x}_1; \\mathbf{w})\\\\f(\\mathbf{x}_2; \\mathbf{w})\\\\ \\vdots \\\\ f(\\mathbf{x}_n; \\mathbf{w})\\end{bmatrix}.\n",
    "$$\n",
    "The second of these is actually a vector-valued function. This term may appear intimidating, but the idea is straightforward. A vector valued function is simply a vector whose elements are themselves defined as *functions*, i.e. it is a vector of functions, rather than a vector of scalars. The idea is so straightforward, that we are going to ignore it for the moment, and barely use it in the derivation. But it will reappear later when we introduce *basis functions*. So we will, for the moment, ignore the dependence of $\\mathbf{f}$ on $\\mathbf{w}$ and $\\mathbf{X}$ and simply summarise it by a vector of numbers\n",
    "$$\n",
    "\\mathbf{f} = \\begin{bmatrix}f_1\\\\f_2\\\\ \\vdots \\\\ f_n\\end{bmatrix}.\n",
    "$$\n",
    "This allows us to write our objective in the folowing, linear algebraic form,\n",
    "$$\n",
    "E(\\mathbf{w}) = (\\mathbf{y} - \\mathbf{f})^\\top(\\mathbf{y} - \\mathbf{f})\n",
    "$$\n",
    "from the rules of inner products.\n",
    "\n",
    "But what of our matrix $\\mathbf{X}$ of input data? At this point, we need to dust off [*matrix-vector multiplication*](http://en.wikipedia.org/wiki/Matrix_multiplication). Matrix multiplication is simply a convenient way of performing many inner products together, and it's exactly what we need to summarise the operation\n",
    "$$\n",
    "f_i = \\mathbf{x}_i^\\top\\mathbf{w}.\n",
    "$$\n",
    "This operation tells us that each element of the vector $\\mathbf{f}$ (our vector valued function) is given by an inner product between $\\mathbf{x}_i$ and $\\mathbf{w}$. In other words it is a series of inner products. Let's look at the definition of matrix multiplication, it takes the form\n",
    "$$\n",
    "\\mathbf{c} = \\mathbf{B}\\mathbf{a}\n",
    "$$\n",
    "where $\\mathbf{c}$ might be a $k$ dimensional vector (which we can intepret as a $k\\times 1$ dimensional matrix), and $\\mathbf{B}$ is a $k\\times k$ dimensional matrix and $\\mathbf{a}$ is a $k$ dimensional vector ($k\\times 1$ dimensional matrix). \n",
    "\n",
    "The result of this multiplication is of the form\n",
    "$$\n",
    "\\begin{bmatrix}c_1\\\\c_2 \\\\ \\vdots \\\\ a_k\\end{bmatrix} = \n",
    "\\begin{bmatrix} b_{1,1} & b_{1, 2} & \\dots & b_{1, k} \\\\\n",
    "b_{2, 1} & b_{2, 2} & \\dots & b_{2, k} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "b_{k, 1} & b_{k, 2} & \\dots & b_{k, k} \\end{bmatrix} \\begin{bmatrix}a_1\\\\a_2 \\\\ \\vdots\\\\ c_k\\end{bmatrix} = \\begin{bmatrix} b_{1, 1}a_1 + b_{1, 2}a_2 + \\dots + b_{1, k}a_k\\\\\n",
    "b_{2, 1}a_1 + b_{2, 2}a_2 + \\dots + b_{2, k}a_k \\\\ \n",
    "\\vdots\\\\ \n",
    "b_{k, 1}a_1 + b_{k, 2}a_2 + \\dots + b_{k, k}a_k\\end{bmatrix}\n",
    "$$\n",
    "so we see that each element of the result, $\\mathbf{a}$ is simply the inner product between each *row* of $\\mathbf{B}$ and the vector $\\mathbf{c}$. Because we have defined each element of $\\mathbf{f}$ to be given by the inner product between each *row* of the design matrix and the vector $\\mathbf{w}$ we now can write the full operation in one matrix multiplication,\n",
    "$$\n",
    "\\mathbf{f} = \\mathbf{X}\\mathbf{w}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.dot(X, w) # np.dot does matrix multiplication in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining this result with our objective function,\n",
    "$$\n",
    "E(\\mathbf{w}) = (\\mathbf{y} - \\mathbf{f})^\\top(\\mathbf{y} - \\mathbf{f})\n",
    "$$\n",
    "we find we have defined the *model* with two equations. One equation tells us the form of our predictive function and how it depends on its parameters, the other tells us the form of our objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error function is: [[9.42352956e+10]]\n"
     ]
    }
   ],
   "source": [
    "resid = (y-f)\n",
    "E = np.dot(resid.T, resid) # matrix multiplication on a single vector is equivalent to a dot product.\n",
    "print(\"Error function is:\", E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 4\n",
    "\n",
    "The prediction for our movie recommender system had the form\n",
    "$$\n",
    "f_{i,j} = \\mathbf{u}_i^\\top \\mathbf{v}_j\n",
    "$$\n",
    "and the objective function was then\n",
    "$$\n",
    "E = \\sum_{i,j} s_{i,j}(y_{i,j} - f_{i, j})^2\n",
    "$$\n",
    "Try writing this down in matrix and vector form. How many of the terms can you do? For each variable and parameter carefully think about whether it should be represented as a matrix or vector. Do as many of the terms as you can. Use $\\LaTeX$ to give your answers and give the *dimensions* of any matrices you create.\n",
    "\n",
    "*20 marks* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 Answer\n",
    "\n",
    "From the previous lab we know that matrices $\\mathbf{U}$, $\\mathbf{V}$ can be represented as:\n",
    "$$\n",
    "\\mathbf{U} = [\\mathbf{u_1}...\\mathbf{u_n}]^\\top, \\mathbf{V} = [\\mathbf{v_1}...\\mathbf{v_n}]^\\top.\n",
    "$$\n",
    "Moreover, we know that $\\mathbf{u_i}$ and $\\mathbf{v_i}$ are vectors of $2\\times 1$ dimension. Thus, the matrices $\\mathbf{U}$, $\\mathbf{V}$ have dimensions $n\\times 2$ and $m\\times 2$ respectively\n",
    "The matrix $\\mathbf{F}$ should containt the elements $f_{i,j} = \\mathbf{u}_i^\\top \\mathbf{v}_j$, so this matrix is going to have dimensions $n \\times m$.\n",
    "The matrix multiplication that we should compute to have as a result the matrix $\\mathbf{F}$ is:\n",
    "$$\n",
    "\\mathbf{F} = \\mathbf{U}\\mathbf{V}^\\top,$$ where $\\mathbf{F}$ dimensions: $n \\times m$.\n",
    "\n",
    "$\\mathbf{S}$, dimensions $n \\times m$\n",
    "\n",
    "$\\mathbf{Y}$, dimensions $n \\times m$\n",
    "\n",
    "$\\mathbf{e_n} = \\begin{bmatrix} 1\\\\ 1\\\\ 1\\end{bmatrix}$, dimensions $n \\times 1$\n",
    "\n",
    "$\\mathbf{e_m} = \\begin{bmatrix} 1\\\\ 1\\end{bmatrix}$, dimensions $m \\times 1$\n",
    "\n",
    "$$\n",
    "E = \\mathbf{e_n^\\top} \\mathbf{S} (\\mathbf{Y} - \\mathbf{F})^\\top(\\mathbf{Y} - \\mathbf{F}) \\mathbf{e_m}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Optimisation\n",
    "\n",
    "Our *model* has now been defined with two equations, the prediction function and the objective function. Next we will use multivariate calculus to define an *algorithm* to fit the model. The separation between model and algorithm is important and is often overlooked. Our model contains a function that shows how it will be used for prediction, and a function that describes the objective function we need to optimise to obtain a good set of parameters. \n",
    "\n",
    "The linear regression model we have described is still the same as the one we fitted above with a coordinate ascent algorithm. We have only played with the notation to obtain the same model in a matrix and vector notation. However, we will now fit this model with a different algorithm, one that is much faster. It is such a widely used algorithm that from the end user's perspective it doesn't even look like an algorithm, it just appears to be a single operation (or function). However, underneath the computer calls an algorithm to find the solution. Further, the algorithm we obtain is very widely used, and because of this it turns out to be highly optimised.\n",
    "\n",
    "Once again we are going to try and find the stationary points of our objective by finding the *stationary points*. However, the stationary points of a multivariate function, are a little bit more complext to find. Once again we need to find the point at which the derivative is zero, but now we need to use  *multivariate calculus* to find it. This involves learning a few additional rules of differentiation (that allow you to do the derivatives of a function with respect to  vector), but in the end it makes things quite a bit easier. We define vectorial derivatives as follows,\n",
    "$$\n",
    "\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}\\mathbf{w}} = \\begin{bmatrix}\\frac{\\partial E(\\mathbf{w})}{\\partial w_1}\\\\\\frac{\\partial E(\\mathbf{w})}{\\partial w_2}\\end{bmatrix}.\n",
    "$$\n",
    "where $\\frac{\\partial E(\\mathbf{w})}{\\partial w_1}$ is the [partial derivative](http://en.wikipedia.org/wiki/Partial_derivative) of the error function with respect to $w_1$.\n",
    "\n",
    "Differentiation through multiplications and additions is relatively straightforward, and since linear algebra is just multiplication and addition, then its rules of diffentiation are quite straightforward too, but slightly more complex than regular derivatives. \n",
    "\n",
    "### Matrix Differentiation\n",
    "\n",
    "We will need two rules of differentiation. The first is diffentiation of an inner product. By remebering that the inner product is made up of multiplication and addition, we can hope that its derivative is quite straightforward, and so it proves to be. We can start by thinking about the definition of the inner product,\n",
    "$$\n",
    "\\mathbf{a}^\\top\\mathbf{z} = \\sum_{i} a_i z_i,\n",
    "$$\n",
    "which if we were to take the derivative with respect to $z_k$ would simply return the gradient of the one term in the sum for which the derivative was non zero, that of $a_k$, so we know that \n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}z_k} \\mathbf{a}^\\top \\mathbf{z} = a_k\n",
    "$$\n",
    "and by our definition of multivariate derivatives we can simply stack all the partial derivatives of this form in a vector to obtain the result that\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}\\mathbf{z}} \\mathbf{a}^\\top \\mathbf{z} = \\mathbf{a}.\n",
    "$$\n",
    "The second rule that's required is differentiation of a 'matrix quadratic'. A scalar quadratic in $z$ with coefficient $c$ has the form $cz^2$. If $\\mathbf{z}$ is a $k\\times 1$ vector and $\\mathbf{C}$ is a $k \\times k$ *matrix* of coefficients then the matrix quadratic form is written as $\\mathbf{z}^\\top \\mathbf{C}\\mathbf{z}$, which is itself a *scalar* quantity, but it is a function of a *vector*. \n",
    "\n",
    "#### Matching Dimensions in Matrix Multiplications\n",
    "\n",
    "There's a trick for telling that it's a scalar result. When you are doing maths with matrices, it's always worth pausing to perform a quick sanity check on the dimensions. Matrix multplication only works when the dimensions match. To be precise, the 'inner' dimension of the matrix must match. What is the inner dimension. If we multiply two matrices $\\mathbf{A}$ and $\\mathbf{B}$, the first of which has $k$ rows and $\\ell$ columns and the second of which has $p$ rows and $q$ columns, then we can check whether the multiplication works by writing the dimensionalities next to each other,\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{B} \\rightarrow (k \\times \\underbrace{\\ell)(p}_\\text{inner dimensions} \\times q) \\rightarrow (k\\times q).\n",
    "$$\n",
    "The inner dimensions are the two inside dimensions, $\\ell$ and $p$. The multiplication will only work if $\\ell=p$. The result of the multiplication will then be a $k\\times q$ matrix: this dimensionality comes from the 'outer dimensions'. Note that matrix multiplication is not [*commutative*](http://en.wikipedia.org/wiki/Commutative_property). And if you change the order of the multiplication, \n",
    "$$\n",
    "\\mathbf{B} \\mathbf{A} \\rightarrow (\\ell \\times \\underbrace{k)(q}_\\text{inner dimensions} \\times p) \\rightarrow (\\ell \\times p).\n",
    "$$\n",
    "firstly it may no longer even work, because now the condition is that $k=q$, and secondly the result could be of a different dimensionality. An exception is if the matrices are square matrices (e.g. same number of rows as columns) and they are both *symmetric*. A symmetric matrix is one for which $\\mathbf{A}=\\mathbf{A}^\\top$, or equivalently, $a_{i,j} = a_{j,i}$ for all $i$ and $j$.  \n",
    "\n",
    "You will need to get used to working with matrices and vectors applying and developing new machine learning techniques. You should have come across them before, but you may not have used them as extensively as we will now do in this course. You should get used to using this trick to check your work and ensure you know what the dimension of an output matrix should be. For our matrix quadratic form, it turns out that we can see it as a special type of inner product.\n",
    "$$\n",
    "\\mathbf{z}^\\top\\mathbf{C}\\mathbf{z} \\rightarrow (1\\times \\underbrace{k) (k}_\\text{inner dimensions}\\times k) (k\\times 1) \\rightarrow \\mathbf{b}^\\top\\mathbf{z}\n",
    "$$\n",
    "where $\\mathbf{b} = \\mathbf{C}\\mathbf{z}$ so therefore the result is a scalar,\n",
    "$$\n",
    "\\mathbf{b}^\\top\\mathbf{z} \\rightarrow (1\\times \\underbrace{k) (k}_\\text{inner dimensions}\\times 1) \\rightarrow (1\\times 1)\n",
    "$$\n",
    "where a $(1\\times 1)$ matrix is recognised as a scalar.\n",
    "\n",
    "This implies that we should be able to differentiate this form, and indeed the rule for its differentiation is slightly more complex than the inner product, but still quite simple,\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}\\mathbf{z}} \\mathbf{z}^\\top\\mathbf{C}\\mathbf{z}= \\mathbf{C}\\mathbf{z} + \\mathbf{C}^\\top \\mathbf{z}.\n",
    "$$\n",
    "Note that in the special case where $\\mathbf{C}$ is symmetric then we have $\\mathbf{C} = \\mathbf{C}^\\top$ and the derivative simplifies to \n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}\\mathbf{z}} \\mathbf{z}^\\top\\mathbf{C}\\mathbf{z}= 2\\mathbf{C}\\mathbf{z}.\n",
    "$$\n",
    "### Differentiating the Objective\n",
    "\n",
    "First, we need to compute the full objective by substituting our prediction function into the objective function to obtain the objective in terms of $\\mathbf{w}$. Doing this we obtain\n",
    "$$\n",
    "E(\\mathbf{w})= (\\mathbf{y} - \\mathbf{X}\\mathbf{w})^\\top (\\mathbf{y} - \\mathbf{X}\\mathbf{w}).\n",
    "$$\n",
    "We now need to differentiate this *quadratic form* to find the minimum. We differentiate with respect to the *vector* $\\mathbf{w}$. But before we do that, we'll expand the brackets in the quadratic form to obtain a series of scalar terms. The rules for bracket expansion across the vectors are similar to those for the scalar system giving,\n",
    "$$\n",
    "(\\mathbf{a} - \\mathbf{b})^\\top (\\mathbf{c} - \\mathbf{d}) = \\mathbf{a}^\\top \\mathbf{c} - \\mathbf{a}^\\top \\mathbf{d} - \\mathbf{b}^\\top \\mathbf{c} + \\mathbf{b}^\\top \\mathbf{d}\n",
    "$$\n",
    "which substituting for $\\mathbf{a} = \\mathbf{c} = \\mathbf{y}$ and $\\mathbf{b}=\\mathbf{d} = \\mathbf{X}\\mathbf{w}$ gives\n",
    "$$\n",
    "E(\\mathbf{w})= \\mathbf{y}^\\top\\mathbf{y} - 2\\mathbf{y}^\\top\\mathbf{X}\\mathbf{w} + \\mathbf{w}^\\top\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w}\n",
    "$$\n",
    "where we used the fact that $\\mathbf{y}^\\top\\mathbf{X}\\mathbf{w}= \\mathbf{w}^\\top\\mathbf{X}^\\top\\mathbf{y}$. Now we can use our rules of differentiation to compute the derivative of this form, which is,\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}\\mathbf{w}}E(\\mathbf{w})=- 2\\mathbf{X}^\\top \\mathbf{y} + 2\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w},\n",
    "$$\n",
    "where we have exploited the fact that $\\mathbf{X}^\\top\\mathbf{X}$ is symmetric to obtain this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 5\n",
    "\n",
    "Use the equivalence between our vector and our matrix formulations of linear regression, alongside our definition of vector derivates, to match the gradients we've computed directly for $\\frac{\\text{d}E(c, m)}{\\text{d}c}$ and $\\frac{\\text{d}E(c, m)}{\\text{d}m}$ to those for $\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}\\mathbf{w}}$.\n",
    "\n",
    "*20 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 Answer\n",
    "\n",
    "Write your answer to the question in this box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Equation for Global Optimum\n",
    "\n",
    "Once again, we need to find the minimum of our objective function. Using our likelihood for multiple input regression we can now minimize for our parameter vector $\\mathbf{w}$. Firstly, just as in the single input case, we seek stationary points by finding parameter vectors that solve for when the gradients are zero,\n",
    "$$\n",
    "\\mathbf{0}=- 2\\mathbf{X}^\\top \\mathbf{y} + 2\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w},\n",
    "$$\n",
    "where $\\mathbf{0}$ is a *vector* of zeros. Rearranging this equation we find the solution to be\n",
    "$$\n",
    "\\mathbf{w} = \\left[\\mathbf{X}^\\top \\mathbf{X}\\right]^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
    "$$ \n",
    "where $\\mathbf{A}^{-1}$ denotes [*matrix inverse*](http://en.wikipedia.org/wiki/Invertible_matrix).\n",
    "\n",
    "### Solving the Multivariate System\n",
    "\n",
    "The solution for $\\mathbf{w}$ is given in terms of a matrix inverse, but computation of a matrix inverse requires, in itself, an algorithm to resolve it. You'll know this if you had to invert, by hand, a $3\\times 3$ matrix in high school. From a numerical stability perspective, it is also best not to compute the matrix inverse directly, but rather to ask the computer to *solve* the  system of linear equations given by\n",
    "$$\\mathbf{X}^\\top\\mathbf{X} \\mathbf{w} = \\mathbf{X}^\\top\\mathbf{y}$$\n",
    "for $\\mathbf{w}$. This can be done in `numpy` using the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can obtain the solution using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can map it back to the liner regression and plot the fit as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = w[1]; c=w[0]\n",
    "f_test = m*x_test + c\n",
    "print(m)\n",
    "print(c)\n",
    "plt.plot(x_test, f_test, 'b-')\n",
    "plt.plot(x, y, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Linear Regression\n",
    "\n",
    "A major advantage of the new system is that we can build a linear regression on a multivariate system. The matrix calculus didn't specify what the length of the vector $\\mathbf{x}$ should be, or equivalently the size of the design matrix. \n",
    "\n",
    "### Movie Body Count Data\n",
    "\n",
    "Let's load back in the movie body count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.movie_body_count()\n",
    "movies = data['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind ourselves of the features we've been provided with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(', '.join(movies.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build a design matrix based on the numeric features: year, Body_Count, Length_Minutes in an effort to predict the rating. We build the design matrix as follows:\n",
    "\n",
    "## Relation to Single Input System\n",
    "\n",
    "Bias as an additional feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = ['Year', 'Body_Count', 'Length_Minutes']\n",
    "X = movies.loc[:, select_features]\n",
    "X['Eins'] = 1 # add a column for the offset\n",
    "y = movies[['IMDB_Rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform a linear regression. But this time, we will create a pandas data frame for the result so we can store it in a form that we can visualise easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "w = pd.DataFrame(data=np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y)),  # solve linear regression here\n",
    "                 index = X.columns,  # columns of X become rows of w\n",
    "                 columns=['regression_coefficient']) # the column of X is the value of regression coefficient\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the residuals to see how good our estimates are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y - np.dot(X, w)).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which shows our model *hasn't* yet done a great job of representation, because the spread of values is large. We can check what the rating is dominated by in terms of regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have to be a little careful about interpretation because our input values live on different scales, however it looks like we are dominated by the bias, with a small negative effect for later films (but bear in mind the years are large, so this effect is probably larger than it looks) and a positive effect for length. So it looks like long earlier films generally do better, but the residuals are so high that we probably haven't modelled the system very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('ui-uNlFHoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('78YNphT90-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution with QR Decomposition\n",
    "\n",
    "Performing a solve instead of a matrix inverse is the more numerically stable approach, but we can do even better. A [QR-decomposition](http://en.wikipedia.org/wiki/QR_decomposition) of a matrix factorises it into a matrix which is an orthogonal matrix $\\mathbf{Q}$, so that $\\mathbf{Q}^\\top \\mathbf{Q} = \\mathbf{I}$. And a matrix which is upper triangular, $\\mathbf{R}$. \n",
    "$$\n",
    "\\mathbf{X}^\\top \\mathbf{X} \\boldsymbol{\\beta} = \\mathbf{X}^\\top \\mathbf{y}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{Q}\\mathbf{R})^\\top (\\mathbf{Q}\\mathbf{R})\\boldsymbol{\\beta} = (\\mathbf{Q}\\mathbf{R})^\\top \\mathbf{y}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{R}^\\top (\\mathbf{Q}^\\top \\mathbf{Q}) \\mathbf{R} \\boldsymbol{\\beta} = \\mathbf{R}^\\top \\mathbf{Q}^\\top \\mathbf{y}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{R}^\\top \\mathbf{R} \\boldsymbol{\\beta} = \\mathbf{R}^\\top \\mathbf{Q}^\\top \\mathbf{y}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{R} \\boldsymbol{\\beta} = \\mathbf{Q}^\\top \\mathbf{y}\n",
    "$$\n",
    "This is a more numerically stable solution because it removes the need to compute $\\mathbf{X}^\\top\\mathbf{X}$ as an intermediate. Computing $\\mathbf{X}^\\top\\mathbf{X}$ is a bad idea because it involves squaring all the elements of $\\mathbf{X}$ and thereby potentially reducing the numerical precision with which we can represent the solution. Operating on $\\mathbf{X}$ directly preserves the numerical precision of the model.\n",
    "\n",
    "This can be more particularly seen when we begin to work with *basis functions* in the next week. Some systems that can be resolved with the QR decomposition can not be resolved by using solve directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "Q, R = np.linalg.qr(X)\n",
    "w = sp.linalg.solve_triangular(R, np.dot(Q.T, y)) \n",
    "w = pd.DataFrame(w, index=X.columns)\n",
    "w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
